[
  {
    "objectID": "tidytuesday-exercise/tidytuesday-exercise.html",
    "href": "tidytuesday-exercise/tidytuesday-exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "Placeholder file for the future Tidy Tuesday exercise."
  },
  {
    "objectID": "starter-analysis-exercise/results/readme.html",
    "href": "starter-analysis-exercise/results/readme.html",
    "title": "Amelia Tristan's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains results produced by the code, such as figures and tables.\nDepending on the size and type of your project, you can either place it all in a single folder or create sub-folders. For instance you could create a folder for figures, another for tables. Or you could create a sub-folder for dataset 1, another for dataset 2. Or you could have a subfolder for exploratory analysis, another for final analysis. The options are endless, choose whatever makes sense for your project. For this template, there is just a a single folder, but having sub-folders is often a good idea."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report2.html",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report2.html",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "",
    "text": "The structure below is one possible setup for a data analysis project (including the course project). For a manuscript, adjust as needed. You don’t need to have exactly these sections, but the content covering those sections should be addressed.\nThis uses MS Word as output format. See here for more information. You can switch to other formats, like html or pdf. See the Quarto documentation for other formats.\nLeo Salazar contributed to this exercise."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report2.html#general-background-information",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report2.html#general-background-information",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.1 General Background Information",
    "text": "2.1 General Background Information\nProvide enough background on your topic that others can understand the why and how of your analysis"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report2.html#description-of-data-and-data-source",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report2.html#description-of-data-and-data-source",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.2 Description of data and data source",
    "text": "2.2 Description of data and data source\nDescribe what the data is, what it contains, where it is from, etc. Eventually this might be part of a methods section."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report2.html#questionshypotheses-to-be-addressed",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report2.html#questionshypotheses-to-be-addressed",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.3 Questions/Hypotheses to be addressed",
    "text": "2.3 Questions/Hypotheses to be addressed\nState the research questions you plan to answer with this analysis.\nTo cite other work (important everywhere, but likely happens first in introduction), make sure your references are in the bibtex file specified in the YAML header above (here dataanalysis_template_references.bib) and have the right bibtex key. Then you can include like this:\nExamples of reproducible research projects can for instance be found in (McKay, Ebell, Billings, et al., 2020; McKay, Ebell, Dale, Shen, & Handel, 2020)"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report2.html#data-aquisition",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report2.html#data-aquisition",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.1 Data aquisition",
    "text": "3.1 Data aquisition\nAs applicable, explain where and how you got the data. If you directly import the data from an online source, you can combine this section with the next."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report2.html#data-import-and-cleaning",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report2.html#data-import-and-cleaning",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.2 Data import and cleaning",
    "text": "3.2 Data import and cleaning\nWrite code that reads in the file and cleans it so it’s ready for analysis. Since this will be fairly long code for most datasets, it might be a good idea to have it in one or several R scripts. If that is the case, explain here briefly what kind of cleaning/processing you do, and provide more details and well documented code somewhere (e.g. as supplement in a paper). All materials, including files that contain code, should be commented well so everyone can follow along."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report2.html#statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report2.html#statistical-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.3 Statistical analysis",
    "text": "3.3 Statistical analysis\nExplain anything related to your statistical analyses."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report2.html#exploratorydescriptive-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report2.html#exploratorydescriptive-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.1 Exploratory/Descriptive analysis",
    "text": "4.1 Exploratory/Descriptive analysis\nUse a combination of text/tables/figures to explore and describe your data. Show the most important descriptive results here. Additional ones should go in the supplement. Even more can be in the R and Quarto files that are part of your project.\nTable 1 shows a summary of the data.\nNote the loading of the data providing a relative path using the ../../ notation. (Two dots means a folder up). You never want to specify an absolute path like C:\\ahandel\\myproject\\results\\ because if you share this with someone, it won’t work for them since they don’t have that path. You can also use the here R package to create paths. See examples of that below. I recommend the here package, but I’m showing the other approach here just in case you encounter it.\n\n\n\n\nTable 1: Data summary table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\ncharacter.min\ncharacter.max\ncharacter.empty\ncharacter.n_unique\ncharacter.whitespace\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\n\ncharacter\nHeight\n0\n1.0000000\n1\n5\n0\n13\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nGender\n0\n1.0000000\n1\n2\n0\n5\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nHair Color\n0\n1.0000000\n2\n7\n0\n9\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nnumeric\nWeight\n1\n0.9285714\nNA\nNA\nNA\nNA\nNA\n602.69231\n1922.24636\n45\n55.00\n70.0\n90.0\n7000\n▇▁▁▁▁\n\n\nnumeric\nInseam\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n55.28571\n30.08304\n0\n49.25\n58.5\n72.5\n95\n▃▂▇▇▆"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report2.html#basic-statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report2.html#basic-statistical-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.2 Basic statistical analysis",
    "text": "4.2 Basic statistical analysis\nTo get some further insight into your data, if reasonable you could compute simple statistics (e.g. simple models with 1 predictor) to look for associations between your outcome(s) and each individual predictor variable. Though note that unless you pre-specified the outcome and main exposure, any “p&lt;0.05 means statistical significance” interpretation is not valid.\nFigure 1 shows a scatterplot figure produced by one of the R scripts.\n\n\n\n\n\n\n\n\nFigure 1: Height and weight stratified by gender."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report2.html#full-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report2.html#full-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.3 Full analysis",
    "text": "4.3 Full analysis\nUse one or several suitable statistical/machine learning methods to analyze your data and to produce meaningful figures, tables, etc. This might again be code that is best placed in one or several separate R scripts that need to be well documented. You want the code to produce figures and data ready for display as tables, and save those. Then you load them here.\nExample Table 2 shows a summary of a linear model fit.\n\n\n\n\nTable 2: Linear model fit table.\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n172.0\nNaN\nNaN\nNaN\n\n\nWeight\n0.2\nNaN\nNaN\nNaN\n\n\nGenderM\n-28.0\nNaN\nNaN\nNaN\n\n\nGenderO\n-34.0\nNaN\nNaN\nNaN"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report2.html#summary-and-interpretation",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report2.html#summary-and-interpretation",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.1 Summary and Interpretation",
    "text": "5.1 Summary and Interpretation\nSummarize what you did, what you found and what it means."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report2.html#strengths-and-limitations",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report2.html#strengths-and-limitations",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.2 Strengths and Limitations",
    "text": "5.2 Strengths and Limitations\nDiscuss what you perceive as strengths and limitations of your analysis."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report2.html#conclusions",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report2.html#conclusions",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.3 Conclusions",
    "text": "5.3 Conclusions\nWhat are the main take-home messages?\nInclude citations in your Rmd file using bibtex, the list of references will automatically be placed at the end\nThis paper (Leek & Peng, 2015) discusses types of analyses.\nThese papers (McKay, Ebell, Billings, et al., 2020; McKay, Ebell, Dale, et al., 2020) are good examples of papers published using a fully reproducible setup similar to the one shown in this template.\nNote that this cited reference will show up at the end of the document, the reference formatting is determined by the CSL file specified in the YAML header. Many more style files for almost any journal are available. You also specify the location of your bibtex reference file in the YAML. You can call your reference file anything you like, I just used the generic word references.bib but giving it a more descriptive name is probably better."
  },
  {
    "objectID": "starter-analysis-exercise/products/readme.html",
    "href": "starter-analysis-exercise/products/readme.html",
    "title": "Amelia Tristan's Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all the products of your project.\nFor a classical academic project, this will be a peer-reviewed manuscript, and should be placed into a manuscript folder.\nFor our case, since we’ll want to put it on the website, we call it a report.\nOften you need a library of references in bibtex format, as well as a CSL style file that determines reference formatting. Since those files might be used by several of the products, I’m placing them in the main products folder. Feel free to re-organize."
  },
  {
    "objectID": "starter-analysis-exercise/data/raw-data/readme.html",
    "href": "starter-analysis-exercise/data/raw-data/readme.html",
    "title": "Amelia Tristan's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains a simple made-up data-set in an Excel file.\nIt contains the variables Height, Weight and Gender of a few imaginary individuals.\nThe dataset purposefully contains some faulty entries that need to be cleaned.\nGenerally, any dataset should contain some meta-data explaining what each variable in the dataset is. (This is often called a Codebook.) For this simple example, the codebook is given as a second sheet in the Excel file.\nThis raw data-set should generally not be edited by hand. It should instead be loaded and processed/cleaned using code."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/readme.html",
    "href": "starter-analysis-exercise/code/processing-code/readme.html",
    "title": "Amelia Tristan's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code for processing data.\nCurrently, there is just a single Quarto file to illustrate how the processing can look like.\nInstead of a Quarto file that contains code, it is also possible to use R scripts or a combination of R scripts and Quarto code. Those approaches are illustrated in the full dataanalysis-template repository."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "href": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "title": "An example cleaning script",
    "section": "",
    "text": "Processing script\nThis Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.\n\n\nSetup\nLoad needed packages. make sure they are installed.\n\nlibrary(readxl) #for loading Excel files\nlibrary(dplyr) #for data processing/cleaning\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\nlibrary(skimr) #for nice visualization of data \n\nWarning: package 'skimr' was built under R version 4.3.3\n\nlibrary(here) #to set paths\n\nhere() starts at C:/Users/ameli/OneDrive/Documents/practicum 2/ameliatristan-p2-portfolio\n\n\n\n\nData loading\nNote that for functions that come from specific packages (instead of base R), I often specify both package and function like so: package::function() that’s not required one could just call the function specifying the package makes it clearer where the function “lives”, but it adds typing. You can do it either way.\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata2.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\n\n\nCheck data\nFirst we can look at the codebook\n\ncodebook &lt;- readxl::read_excel(data_location, sheet =\"Codebook\")\nprint(codebook)\n\n# A tibble: 5 × 3\n  `Variable Name` `Variable Definition`                 `Allowed Values`        \n  &lt;chr&gt;           &lt;chr&gt;                                 &lt;chr&gt;                   \n1 Height          height in centimeters                 numeric value &gt;0 or NA  \n2 Weight          weight in kilograms                   numeric value &gt;0 or NA  \n3 Gender          identified gender (male/female/other) M/F/O/NA                \n4 Inseam Length   inseam in centimeters                 numeric value &gt;0 or NA  \n5 Hair Color      hair color, natural or other          black/brown/blond/white…\n\n\nSeveral ways of looking at the data\n\ndplyr::glimpse(rawdata)\n\nRows: 14\nColumns: 5\n$ Height       &lt;chr&gt; \"180\", \"175\", \"sixty\", \"178\", \"192\", \"6\", \"156\", \"166\", \"…\n$ Weight       &lt;dbl&gt; 80, 70, 60, 76, 90, 55, 90, 110, 54, 7000, NA, 45, 55, 50\n$ Gender       &lt;chr&gt; \"M\", \"O\", \"F\", \"F\", \"NA\", \"F\", \"O\", \"M\", \"N\", \"M\", \"F\", \"…\n$ Inseam       &lt;dbl&gt; 1, 74, 55, 91, 95, 89, 68, 62, 23, 49, 0, 50, 52, 65\n$ `Hair Color` &lt;chr&gt; \"black\", \"39\", \"brown\", \"l brown\", \"other\", \"black\", \"oth…\n\nsummary(rawdata)\n\n    Height              Weight          Gender              Inseam     \n Length:14          Min.   :  45.0   Length:14          Min.   : 0.00  \n Class :character   1st Qu.:  55.0   Class :character   1st Qu.:49.25  \n Mode  :character   Median :  70.0   Mode  :character   Median :58.50  \n                    Mean   : 602.7                      Mean   :55.29  \n                    3rd Qu.:  90.0                      3rd Qu.:72.50  \n                    Max.   :7000.0                      Max.   :95.00  \n                    NA's   :1                                          \n  Hair Color       \n Length:14         \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\nhead(rawdata)\n\n# A tibble: 6 × 5\n  Height Weight Gender Inseam `Hair Color`\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       \n1 180        80 M           1 black       \n2 175        70 O          74 39          \n3 sixty      60 F          55 brown       \n4 178        76 F          91 l brown     \n5 192        90 NA         95 other       \n6 6          55 F          89 black       \n\nskimr::skim(rawdata)\n\n\nData summary\n\n\nName\nrawdata\n\n\nNumber of rows\n14\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHeight\n0\n1\n1\n5\n0\n13\n0\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nHair Color\n0\n1\n2\n7\n0\n9\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nWeight\n1\n0.93\n602.69\n1922.25\n45\n55.00\n70.0\n90.0\n7000\n▇▁▁▁▁\n\n\nInseam\n0\n1.00\n55.29\n30.08\n0\n49.25\n58.5\n72.5\n95\n▃▂▇▇▆\n\n\n\n\n\n\n\nCleaning\nBy inspecting the data as done above, we find some problems that need addressing:\nFirst, there is an entry for height which says “sixty” instead of a number. Does that mean it should be a numeric 60? It somehow doesn’t make sense since the weight is 60kg, which can’t happen for a 60cm person (a baby). Since we don’t know how to fix this, we might decide to remove the person. This “sixty” entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn’t very meaningful. So let’s fix that first.\n\nd1 &lt;- rawdata %&gt;% dplyr::filter( Height != \"sixty\" ) %&gt;% \n                  dplyr::mutate(Height = as.numeric(Height))\nskimr::skim(d1)\n\n\nData summary\n\n\nName\nd1\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nHair Color\n0\n1\n2\n7\n0\n8\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n151.62\n46.46\n6\n154.00\n165\n175\n192\n▁▁▁▂▇\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\nInseam\n0\n1.00\n55.31\n31.31\n0\n49.00\n62\n74\n95\n▃▂▆▇▆\n\n\n\n\nhist(d1$Height)\n\n\n\n\n\n\n\n\nNow we see that there is one person with a height of 6. That could be a typo, or someone mistakenly entered their height in feet. Since we unfortunately don’t know, we might need to remove this person, which we’ll do here.\n\nd2 &lt;- d1 %&gt;% dplyr::mutate( Height = replace(Height, Height==\"6\",round(6*30.48,0)) )\nskimr::skim(d2)\n\n\nData summary\n\n\nName\nd2\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nHair Color\n0\n1\n2\n7\n0\n8\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n165.23\n16.52\n133\n155.00\n166\n178\n192\n▂▇▆▆▃\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\nInseam\n0\n1.00\n55.31\n31.31\n0\n49.00\n62\n74\n95\n▃▂▆▇▆\n\n\n\n\n\nHeight values seem ok now.\nNow let’s look at the Weight variable. There is a person with weight of 7000, which is impossible, and one person with missing weight. To be able to analyze the data, we’ll remove those individuals as well.\n\nd3 &lt;- d2 %&gt;%  dplyr::filter(Weight != 7000) %&gt;% tidyr::drop_na()\nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nHair Color\n0\n1\n2\n7\n0\n8\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179.0\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85.0\n110\n▇▂▃▃▂\n\n\nInseam\n0\n1\n60.91\n28.85\n1\n51.0\n65\n81.5\n95\n▂▂▃▇▆\n\n\n\n\n\nNow checking the Gender variable. Gender should be a categorical/factor variable but is loaded as character. We can fix that with simple base R code to mix things up.\n\nd3$Gender &lt;- as.factor(d3$Gender)  \nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHair Color\n0\n1\n2\n7\n0\n8\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n5\nM: 4, F: 3, O: 2, N: 1\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179.0\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85.0\n110\n▇▂▃▃▂\n\n\nInseam\n0\n1\n60.91\n28.85\n1\n51.0\n65\n81.5\n95\n▂▂▃▇▆\n\n\n\n\n\nNow we see that there is another NA, but it’s not NA from R, instead it was loaded as character and is now considered as a category. Well proceed here by removing that individual with that NA entry. Since this keeps an empty category for Gender, I’m also using droplevels() to get rid of it.\n\nd4 &lt;- d3 %&gt;% dplyr::filter( !(Gender %in% c(\"NA\",\"N\")) ) %&gt;% droplevels()\nskimr::skim(d4)\n\n\nData summary\n\n\nName\nd4\n\n\nNumber of rows\n9\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHair Color\n0\n1\n2\n7\n0\n7\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n3\nM: 4, F: 3, O: 2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n165.67\n15.98\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nWeight\n0\n1\n70.11\n21.25\n45\n55\n70\n80\n110\n▇▂▃▂▂\n\n\nInseam\n0\n1\n61.33\n26.74\n1\n52\n65\n74\n91\n▂▁▅▇▇\n\n\n\n\n\nAll done, data is clean now.\nLet’s assign at the end to some final variable, this makes it easier to add further cleaning steps above.\n\nprocesseddata &lt;- d4\n\n\n\nSave data\nFinally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data: http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata\n\nsave_data_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\nsaveRDS(processeddata, file = save_data_location)\n\nNote the use of the here package and here command to specify a path relative to the main project directory, that is the folder that contains the .Rproj file. Always use this approach instead of hard-coding file paths that only exist on your computer.\n\n\nNotes\nRemoving anyone observation with “faulty” or missing data is one approach. It’s often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information)."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/eda2.html",
    "href": "starter-analysis-exercise/code/eda-code/eda2.html",
    "title": "An example exploratory analysis script",
    "section": "",
    "text": "This Quarto file loads the cleaned data and does some exploring.\nI’m only showing it the way where the code is included in the file. As described in the processing_code materials, I currently prefer the approach of having R code in a separate file and pulling it in.\nBut I already had this written and haven’t yet re-done it that way. Feel free to redo and send a pull request on GitHub :)\nAgain, it is largely a matter of preference and what makes the most sense to decide if one wants to have code inside Quarto files, or as separate R files. And sometimes, an R script with enough comments is good enough and one doesn’t need a Quarto file.\nAlso note that while here I split cleaning and exploring, this is iterative. You saw that as part of the processing, we already had to explore the data somewhat to understand how to clean it. In general, as you explore, you’ll find things that need cleaning. As you clean, you can explore more. Therefore, at times it might make more sense to combine the cleaning and exploring code parts into a single R or Quarto file. Or split things in any other logical way.\nAs part of the exploratory analysis, you should produce plots or tables or other summary quantities for the most interesting/important quantities in your data. Depending on the total number of variables in your dataset, explore all or some of the others. Figures produced here might be histograms or density plots, correlation plots, etc. Tables might summarize your data.\nStart by exploring one variable at a time. Then continue by creating plots or tables of the outcome(s) of interest and the predictor/exposure/input variables you are most interested in. If your dataset is small, you can do that for all variables.\nPlots produced here can be scatterplots, boxplots, violinplots, etc. Tables can be simple 2x2 tables or larger ones.\n\nSetup\n\n#load needed packages. make sure they are installed.\nlibrary(here) #for data loading/saving\n\nhere() starts at C:/Users/ameli/OneDrive/Documents/practicum 2/ameliatristan-p2-portfolio\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(skimr)\n\nWarning: package 'skimr' was built under R version 4.3.3\n\n#update.packages(\"ggplot2\")\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nLoad the data.\n\n#Path to data. Note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata2.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\n\nView(rawdata)\n\n\n\nData exploration through tables\nShowing a bit of code to produce and save a summary table.\n\nsummary_df = skimr::skim(rawdata)\nprint(summary_df)\n\n── Data Summary ────────────────────────\n                           Values \nName                       rawdata\nNumber of rows             14     \nNumber of columns          5      \n_______________________           \nColumn type frequency:            \n  character                3      \n  numeric                  2      \n________________________          \nGroup variables            None   \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Height                0             1   1   5     0       13          0\n2 Gender                0             1   1   2     0        5          0\n3 Hair Color            0             1   2   7     0        9          0\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate  mean     sd p0  p25  p50  p75 p100\n1 Weight                1         0.929 603.  1922.  45 55   70   90   7000\n2 Inseam                0         1      55.3   30.1  0 49.2 58.5 72.5   95\n  hist \n1 ▇▁▁▁▁\n2 ▃▂▇▇▆\n\n# save to file\nsummarytable_file = here(\"starter-analysis-exercise\",\"results\", \"tables-files\", \"summarytable.rds\")\nsaveRDS(summary_df, file = summarytable_file)\n\nWe are saving the results to the results/tables folder. Structure the folders inside results such that they make sense for your specific analysis. Provide enough documentation that someone can understand what you are doing and what goes where. readme.md files inside each folder are a good idea.\n\n\nData exploration through figures\nBoxplot\nIt is very difficults to\n\nggplot(rawdata,aes(`Hair Color`,Height))+geom_boxplot()\n\n\n\n\n\n\n\n\nScatterPlot\n\nggplot(rawdata,aes(x = `Hair Color`, y = Height)) +\n  geom_point()\n\n\n\n\n\n\n\n\nHistogram plots for the continuous outcomes.\nHeight first.\n\n#p1 &lt;- rawdata %&gt;% ggplot(aes(x = Height)) + geom_histogram() \n#plot(p1)\n#figure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-distribution.png\")\n#ggsave(filename = figure_file, plot=p1) \n\nNow weights.\n\np2 &lt;- rawdata %&gt;% ggplot(aes(x=Weight)) + geom_histogram() \nplot(p2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"weight-distribution.png\")\nggsave(filename = figure_file, plot=p2) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nNow height as function of weight.\n\np3 &lt;- rawdata %&gt;% ggplot(aes(x=Height, y=Weight)) + geom_point() + geom_smooth(method='lm')\nplot(p3)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight.png\")\nggsave(filename = figure_file, plot=p3) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 1 row containing non-finite outside the scale range (`stat_smooth()`).\nRemoved 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nOnce more height as function of weight, stratified by gender. Note that there is so little data, it’s a bit silly. But we’ll plot it anyway.\n\np4 &lt;- rawdata %&gt;% ggplot(aes(x=Height, y=Weight, color = Gender)) + geom_point() + geom_smooth(method='lm')\nplot(p4)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight-stratified.png\")\nggsave(filename = figure_file, plot=p4) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 1 row containing non-finite outside the scale range (`stat_smooth()`).\nRemoved 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\nNotes\nFor your own explorations, tables and figures can be “quick and dirty”. As long as you can see what’s going on, there is no need to polish them. That’s in contrast to figures you’ll produce for your final products (paper, report, presentation, website, etc.). Those should look as nice, polished and easy to understand as possible."
  },
  {
    "objectID": "starter-analysis-exercise/code/analysis-code/readme.html",
    "href": "starter-analysis-exercise/code/analysis-code/readme.html",
    "title": "Amelia Tristan's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory analysis and statistical analysis on the processed/cleaned data. The code produces a few tables and figures, which are saved in the results folder.\nIt’s the same code done 3 times:\n\nFirst, there is an R script that you can run which does all the computations.\nSecond, there is a Quarto file which contains exactly the same code as the R script.\nThird, my current favorite, is a Quarto file with an approach where the code is pulled in from the R script and run.\n\nThe last version has the advantage of having code in one place for easy writing/debugging, and then being able to pull the code into the Quarto file for a nice combination of text/commentary and code.\nEach way of doing this is a reasonable approach, pick whichever one you prefer or makes the most sense for your setup. Whichever approach you choose, add ample documentation/commentary so you and others can easily understand what’s going on and what is done."
  },
  {
    "objectID": "presentation-exercise/presentation-exercise.html",
    "href": "presentation-exercise/presentation-exercise.html",
    "title": "Presentation Exercise",
    "section": "",
    "text": "#Original\n #Prompts and Results\nUsing ChatGPT, I produced a publication worthy visualization similar to the one published here: https://fivethirtyeight.com/videos/the-ultimate-halloween-candy-power-ranking/ .\nThe following are the prompts and resulting code from CGPT:\nPrompt 1: Can you write code in R to recreate this chart? *attached screenshot of chart Result 1: A bare bones code structure that built its own data frame from a set of candy names and win percentages.\nPrompt 2: Can you recreate the chart using this data? *attached .csv file Result 2: Code that created the data frame from the csv file and a ggplot with only the top 18 ranking candies.\nPrompt 3: Can you make the plot interactive? Result 3: Same code as result 2, except using plotly to create the interactive chart instead of using ggplot.\nPrompt 4: Can you add their ranking number next to the candy name? Result 4: Same code as result 3, plus a new variable called rank that is displayed next to the candy name in the ploty plot.\nPrompt 5: Can you write code that displays the rank, candy name, then win percentage bar within a table? Result 5: A formattable table that displays the candy name, win percentage in a color coded single-bar graph, and rank number.\n#Result 1 A bare bones code that created its own data frame for candy_data.\n#Result 2\n\n# Load necessary libraries\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(readr)\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Load the data\ncandy_data &lt;- read_csv(\"candy-data.csv\")\n\nRows: 85 Columns: 13\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): competitorname\ndbl (12): chocolate, fruity, caramel, peanutyalmondy, nougat, crispedricewaf...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Select relevant columns and rename for clarity\ncandy_data &lt;- candy_data %&gt;% \n  select(CANDY = competitorname, WIN_PERCENTAGE = winpercent)\n\n# Sort data by WIN_PERCENTAGE in descending order\ncandy_data &lt;- candy_data %&gt;%\n  arrange(desc(WIN_PERCENTAGE)) %&gt;%\n  head(18) # Take the top 18 candies\n\n# Plot the data\nggplot(candy_data, aes(x = reorder(CANDY, WIN_PERCENTAGE), y = WIN_PERCENTAGE)) +\n  geom_bar(stat = \"identity\", fill = \"orange\") +\n  coord_flip() +\n  labs(title = \"Candy Ranking by Win Percentage\",\n       x = \"Candy\",\n       y = \"Win Percentage\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 8))\n\n\n\n\n\n\n\n\n#Result 3\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n# Load the data\ncandy_data &lt;- read_csv(\"candy-data.csv\")\n\nRows: 85 Columns: 13\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): competitorname\ndbl (12): chocolate, fruity, caramel, peanutyalmondy, nougat, crispedricewaf...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Select relevant columns and rename for clarity\ncandy_data &lt;- candy_data %&gt;% \n  select(CANDY = competitorname, WIN_PERCENTAGE = winpercent)\n\n# Sort data by WIN_PERCENTAGE in descending order\ncandy_data &lt;- candy_data %&gt;%\n  arrange(desc(WIN_PERCENTAGE)) %&gt;%\n  head(18) # Take the top 18 candies\n\n# Create the ggplot chart\np &lt;- ggplot(candy_data, aes(x = reorder(CANDY, WIN_PERCENTAGE), y = WIN_PERCENTAGE, text = paste(\"Candy:\", CANDY, \"&lt;br&gt;Win Percentage:\", WIN_PERCENTAGE))) +\n  geom_bar(stat = \"identity\", fill = \"orange\") +\n  coord_flip() +\n  labs(title = \"Candy Ranking by Win Percentage\",\n       x = \"Candy\",\n       y = \"Win Percentage\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 8))\n\n# Convert the ggplot chart to an interactive plotly chart\ninteractive_plot &lt;- ggplotly(p, tooltip = \"text\")\n\n# Display the interactive chart\ninteractive_plot\n\n\n\n\n\n#Result 4\n\n# Sort data by WIN_PERCENTAGE in descending order and add ranking\ncandy_data &lt;- candy_data %&gt;%\n  arrange(desc(WIN_PERCENTAGE)) %&gt;%\n  head(18) %&gt;%\n  mutate(RANK = row_number(),\n         CANDY_LABEL = paste(RANK, CANDY, sep = \". \"))\n\n# Create the ggplot chart\np &lt;- ggplot(candy_data, aes(x = reorder(CANDY_LABEL, WIN_PERCENTAGE), y = WIN_PERCENTAGE, text = paste(\"Candy:\", CANDY, \"&lt;br&gt;Win Percentage:\", WIN_PERCENTAGE))) +\n  geom_bar(stat = \"identity\", fill = \"orange\") +\n  coord_flip() +\n  labs(title = \"Candy Ranking by Win Percentage\",\n       x = \"Candy\",\n       y = \"Win Percentage\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 8))\n\n# Convert the ggplot chart to an interactive plotly chart\ninteractive_plot &lt;- ggplotly(p, tooltip = \"text\")\n\n# Display the interactive chart\ninteractive_plot\n\n\n\n\n\n#Result 5\n\n# Load necessary libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(formattable)\n\nWarning: package 'formattable' was built under R version 4.3.3\n\n\n\nAttaching package: 'formattable'\n\n\nThe following object is masked from 'package:plotly':\n\n    style\n\n# Sort data by WIN_PERCENTAGE in descending order and add ranking\ncandy_data &lt;- candy_data %&gt;%\n  arrange(desc(WIN_PERCENTAGE)) %&gt;%\n  head(18) %&gt;%\n  mutate(RANK = row_number())\n\n# Create a formattable table\nformatted_table &lt;- formattable(candy_data, list(\n  RANK = formatter(\"span\", style = ~ style(color = \"black\")),\n  CANDY = formatter(\"span\", style = ~ style(color = \"black\")),\n  WIN_PERCENTAGE = formatter(\"span\",\n                             style = x ~ style(display = \"block\",\n                                               direction = \"rtl\",\n                                               \"border-radius\" = \"4px\",\n                                               \"padding-right\" = \"2px\",\n                                               \"background-color\" = ifelse(x &gt; 75, \"orange\", ifelse(x &gt; 50, \"lightgreen\", \"lightblue\")),\n                                               width = paste0(x, \"%\")),\n                             x ~ sprintf(\"%.1f%%\", x))\n))\n\n# Display the formatted table\nformatted_table\n\n\n\n\n\nCANDY\n\n\nWIN_PERCENTAGE\n\n\nRANK\n\n\nCANDY_LABEL\n\n\n\n\n\n\nReese’s Peanut Butter cup \n\n\n84.2%\n\n\n1\n\n\n\nReese’s Peanut Butter cup\n\n\n\n\nReese’s Miniatures \n\n\n81.9%\n\n\n2\n\n\n\nReese’s Miniatures\n\n\n\n\nTwix \n\n\n81.6%\n\n\n3\n\n\n\nTwix\n\n\n\n\nKit Kat \n\n\n76.8%\n\n\n4\n\n\n\nKit Kat\n\n\n\n\nSnickers \n\n\n76.7%\n\n\n5\n\n\n\nSnickers\n\n\n\n\nReese’s pieces \n\n\n73.4%\n\n\n6\n\n\n\nReese’s pieces\n\n\n\n\nMilky Way \n\n\n73.1%\n\n\n7\n\n\n\nMilky Way\n\n\n\n\nReese’s stuffed with pieces\n\n\n72.9%\n\n\n8\n\n\n\nReese’s stuffed with pieces\n\n\n\n\nPeanut butter M&M’s \n\n\n71.5%\n\n\n9\n\n\n\nPeanut butter M&M’s\n\n\n\n\nNestle Butterfinger \n\n\n70.7%\n\n\n10\n\n\n\nNestle Butterfinger\n\n\n\n\nPeanut M&Ms \n\n\n69.5%\n\n\n11\n\n\n\nPeanut M&Ms\n\n\n\n\n3 Musketeers \n\n\n67.6%\n\n\n12\n\n\n\n3 Musketeers\n\n\n\n\nStarburst \n\n\n67.0%\n\n\n13\n\n\n\nStarburst\n\n\n\n\n100 Grand \n\n\n67.0%\n\n\n14\n\n\n\n100 Grand\n\n\n\n\nM&M’s \n\n\n66.6%\n\n\n15\n\n\n\nM&M’s\n\n\n\n\nNestle Crunch \n\n\n66.5%\n\n\n16\n\n\n\nNestle Crunch\n\n\n\n\nRolo \n\n\n65.7%\n\n\n17\n\n\n\nRolo\n\n\n\n\nMilky Way Simply Caramel \n\n\n64.4%\n\n\n18\n\n\n\nMilky Way Simply Caramel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n:::\n#My Tweaked Version\n\ncandy_data2 = read_csv(\"candy-data.csv\")\n\nRows: 85 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): competitorname\ndbl (12): chocolate, fruity, caramel, peanutyalmondy, nougat, crispedricewaf...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Select relevant columns and rename for clarity\ncandy_data2 &lt;- candy_data2 %&gt;% \n  select(CANDY = competitorname, WIN_PERCENTAGE = winpercent)\n\n# Sort data by WIN_PERCENTAGE in descending order and add ranking\ncandy_data2 &lt;- candy_data2 %&gt;%\n  arrange(desc(WIN_PERCENTAGE)) %&gt;%\n  mutate(RANK = row_number())\n\n# Customize column names\ncandy_data2 &lt;- candy_data2 %&gt;%\n  rename(`Win Percentage` = WIN_PERCENTAGE)\n\n# Create a formattable table\nformatted_table &lt;- formattable(candy_data2, list(\n  RANK = formatter(\"span\", style = ~ style(color = \"black\")),\n  CANDY = formatter(\"span\", style = ~ style(color = \"black\")),\n  `Win Percentage` = formatter(\"span\",\n                             style = x ~ style(display = \"block\",\n                                               direction = \"rtl\",\n                                               \"border-radius\" = \"4px\",\n                                               \"padding-right\" = \"2px\",\n                                               \"background-color\" = ifelse(x &gt; 75, \"orange\", ifelse(x &gt; 50, \"lightgreen\", \"lightblue\")),\n                                               width = paste0(x, \"%\")),\n                             x ~ sprintf(\"%.1f%%\", x))\n))\n\n# Add a label to the table\nhtml_header &lt;- \"&lt;h2 style='text-align: center;'&gt;Halloween Candies Ranked&lt;/h2&gt;\"\nhtml_table &lt;- as.htmlwidget(formatted_table)\nhtml_table &lt;- htmltools::tagList(htmltools::HTML(html_header), html_table)\n\n# Display the formatted table with the header\nhtmltools::browsable(html_table)\n\nHalloween Candies Ranked\n\n\n\n\n#Another Table\n\ncandy_data3 = read_csv(\"candy-data.csv\")\n\nRows: 85 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): competitorname\ndbl (12): chocolate, fruity, caramel, peanutyalmondy, nougat, crispedricewaf...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Select relevant columns and rename for clarity\ncandy_data3 &lt;- candy_data3 %&gt;% filter(chocolate == 1 | caramel == 1) %&gt;% \n  select(CANDY = competitorname, WIN_PERCENTAGE = winpercent)\n\n# Sort data by WIN_PERCENTAGE in descending order and add ranking\ncandy_data3 &lt;- candy_data3 %&gt;%\n  arrange(desc(WIN_PERCENTAGE)) %&gt;%\n  mutate(RANK = row_number())\n\n# Customize column names\ncandy_data3 &lt;- candy_data3 %&gt;%\n  rename(`Win Percentage` = WIN_PERCENTAGE)\n\n# Create a formattable table\nformatted_table &lt;- formattable(candy_data3, list(\n  RANK = formatter(\"span\", style = ~ style(color = \"black\")),\n  TYPE = formatter(\"span\", style = ~ style(color = \"black\")),\n  `Win Percentage` = formatter(\"span\",\n                             style = x ~ style(display = \"block\",\n                                               direction = \"rtl\",\n                                               \"border-radius\" = \"4px\",\n                                               \"padding-right\" = \"2px\",\n                                               \"background-color\" = ifelse(x &gt; 75, \"brown\", ifelse(x &gt; 50, \"tan\", \"beige\")),\n                                               width = paste0(x, \"%\")),\n                             x ~ sprintf(\"%.1f%%\", x))\n))\n\n# Add a label to the table\nhtml_header &lt;- \"&lt;h2 style='text-align: center;'&gt;Halloween Candies Ranked: Chocolate & Caramel Edition&lt;/h2&gt;\"\nhtml_table &lt;- as.htmlwidget(formatted_table)\nhtml_table &lt;- htmltools::tagList(htmltools::HTML(html_header), html_table)\n\n# Display the formatted table with the header\nhtmltools::browsable(html_table)\n\nHalloween Candies Ranked: Chocolate & Caramel Edition"
  },
  {
    "objectID": "data-exercise/data-exercise.html",
    "href": "data-exercise/data-exercise.html",
    "title": "Data Exercise",
    "section": "",
    "text": "library(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n#seed for reproducibility\nset.seed(92)\n\n\n#start generating data\nn = 1200\n\n#bone breaks in adolescents\nage &lt;- round(runif(n, 10, 18), 0)\nbreak_type &lt;- c(\"compound\", \"spiral\", \"transverse\", \"greenstick\", \"comminuted\")\nbone_breaks &lt;- sample(break_type, n, replace = TRUE, prob = c(0.2, 0.15, 0.4, 0.38, 0.29))\n\n\nbreak_num &lt;- as.numeric(factor(bone_breaks, levels = break_type))\n\n#surgery cost to fix broken bone\nsurgery_cost &lt;- round(1500 + age * 10 + break_num * 200 + rnorm(n, mean = 0, sd = 50), 0)\n#time in hours for surgery\nsurgery_time &lt;- round(12 - age * 0.1 + rnorm(n, mean = 0, sd = 5), 1)\n\n#percent of recovery without complications\nrecovery &lt;- round(5 + surgery_cost * 0.005 - surgery_time * 0.05 + rnorm(n, mean = 0, sd = 1), 1)\n\n#data frame for break data\nbreak_data &lt;- data.frame(age, break_type, surgery_cost, surgery_time, recovery)\n\nsummary(break_data)\n\n      age         break_type         surgery_cost   surgery_time  \n Min.   :10.00   Length:1200        Min.   :1729   Min.   :-7.00  \n 1st Qu.:12.00   Class :character   1st Qu.:2148   1st Qu.: 7.40  \n Median :14.00   Mode  :character   Median :2292   Median :10.60  \n Mean   :14.01                      Mean   :2296   Mean   :10.58  \n 3rd Qu.:16.00                      3rd Qu.:2487   3rd Qu.:13.70  \n Max.   :18.00                      Max.   :2823   Max.   :32.20  \n    recovery    \n Min.   :11.00  \n 1st Qu.:14.90  \n Median :16.10  \n Mean   :16.01  \n 3rd Qu.:17.20  \n Max.   :20.50  \n\n\n\n#surgery cost by age\nggplot(break_data, aes(x = age, y = surgery_cost)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n#surgery cost by break type\nggplot(break_data, aes(x = break_type, y = surgery_cost)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n#surgery time by age\nggplot(break_data, aes(x = age, y = surgery_time)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n#surgery cost by time\nggplot(break_data, aes(x = surgery_time, y = surgery_cost)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n#recovery rate by surgery time\nggplot(break_data, aes(x = surgery_time, y = recovery)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n###Fit simple models to the data\n\n#cost by age and break type model\ncost_model &lt;- lm(surgery_cost ~ age + break_type, data = break_data)\nsummary(cost_model)\n\n\nCall:\nlm(formula = surgery_cost ~ age + break_type, data = break_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-554.64 -150.89   -1.69  189.80  524.72 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          2202.709     46.912  46.954   &lt;2e-16 ***\nage                     5.856      3.172   1.846   0.0651 .  \nbreak_typecompound     12.296     23.519   0.523   0.6012    \nbreak_typegreenstick   24.524     23.512   1.043   0.2971    \nbreak_typespiral       16.426     23.525   0.698   0.4852    \nbreak_typetransverse    1.879     23.568   0.080   0.9365    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 257.5 on 1194 degrees of freedom\nMultiple R-squared:  0.003977,  Adjusted R-squared:  -0.0001939 \nF-statistic: 0.9535 on 5 and 1194 DF,  p-value: 0.4453\n\n#time by age model\ntime_model &lt;- lm(surgery_time ~ age, data = break_data)\nsummary(time_model)\n\n\nCall:\nlm(formula = surgery_time ~ age, data = break_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.1776  -3.2440   0.0192   3.1614  21.8880 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  12.4627     0.8666  14.382   &lt;2e-16 ***\nage          -0.1344     0.0610  -2.204   0.0277 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.973 on 1198 degrees of freedom\nMultiple R-squared:  0.004037,  Adjusted R-squared:  0.003205 \nF-statistic: 4.856 on 1 and 1198 DF,  p-value: 0.02774\n\n#recovery rate by cost model\nrecovery_model &lt;- lm(recovery ~ surgery_cost + surgery_time, data = break_data)\nsummary(recovery_model)\n\n\nCall:\nlm(formula = recovery ~ surgery_cost + surgery_time, data = break_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9103 -0.7416 -0.0134  0.7328  3.1936 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5.045455   0.268072  18.821   &lt;2e-16 ***\nsurgery_cost  0.005007   0.000114  43.902   &lt;2e-16 ***\nsurgery_time -0.050294   0.005895  -8.531   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.016 on 1197 degrees of freedom\nMultiple R-squared:  0.6222,    Adjusted R-squared:  0.6215 \nF-statistic: 985.6 on 2 and 1197 DF,  p-value: &lt; 2.2e-16\n\n#exploring another type of model\nrecovery_glm &lt;- glm(recovery ~ surgery_cost + surgery_time, family = gaussian(link = \"identity\"), data = break_data)\nsummary(recovery_glm)\n\n\nCall:\nglm(formula = recovery ~ surgery_cost + surgery_time, family = gaussian(link = \"identity\"), \n    data = break_data)\n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5.045455   0.268072  18.821   &lt;2e-16 ***\nsurgery_cost  0.005007   0.000114  43.902   &lt;2e-16 ***\nsurgery_time -0.050294   0.005895  -8.531   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 1.032061)\n\n    Null deviance: 3269.7  on 1199  degrees of freedom\nResidual deviance: 1235.4  on 1197  degrees of freedom\nAIC: 3448.3\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "cdcdata-exercise/cdcdata-exercise.html",
    "href": "cdcdata-exercise/cdcdata-exercise.html",
    "title": "Assignment 5",
    "section": "",
    "text": "I am exploring the CDC records of botulism cases from 1899 to 2017. This dataset was last updated in May 2019. All records are non-infant cases.\n\nlibrary(tidyverse)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\n\n#Botulism records from 1899 to 2017 by transmission and toxin type, state, and frequency\nbotulism = read.csv(\"Botulism_20240704.csv\")\n\n\n#change to factor\nbotulism$BotType = as.factor(botulism$BotType)\nbotulism$ToxinType = as.factor(botulism$ToxinType)\nbotulism$State = as.factor(botulism$State)\n\n#filtering out NA entries. State is only variable with null entries\nbotulism = botulism %&gt;% dplyr::filter(!is.na(State))\n\n#stats summary\nsummary(botulism)\n\n        State           Year           BotType       ToxinType  \n California: 343   Min.   :1899   Foodborne: 899   A      :958  \n Washington: 143   1st Qu.:1976   Infant   :1124   B      :778  \n Texas     : 107   Median :1992   Other    :  72   Unknown:369  \n Colorado  :  98   Mean   :1985   Wound    : 151   E      : 72  \n Oregon    :  95   3rd Qu.:2006                    F      : 41  \n Alaska    :  88   Max.   :2017                    Bf     :  8  \n (Other)   :1372                                   (Other): 20  \n     Count       \n Min.   : 1.000  \n 1st Qu.: 1.000  \n Median : 1.000  \n Mean   : 3.223  \n 3rd Qu.: 3.000  \n Max.   :59.000  \n                 \n\n\n\n#histogram of cases by year\nby_year = ggplot(data = botulism, aes(x = Year)) + geom_histogram(binwidth = 2, color = \"black\", fill = \"green\" )\nby_year\n\n\n\n\n\n\n\n#filtering data to only include top states\ntop_states = botulism %&gt;% dplyr::filter(State == c(\"California\", \"Washington\", \"Texas\", \"Colorado\", \"Oregon\", \"Alaska\"))\n\n#contraction type by top state\nby_bot_state = ggplot(data = top_states, aes(x = State )) + geom_bar(color = \"black\", fill = \"pink\") + facet_wrap(~BotType, scales = \"free\") + labs(x = \"State\", y = \"Count\", title = \"Case Count by Top  State and Contraction Type\")\nby_bot_state\n\n\n\n\n\n\n\n#toxin type by top state\nby_tox_state = ggplot(data = top_states, aes(x = State )) + geom_bar(color = \"black\", fill = \"purple\") + facet_wrap(~ToxinType, scales = \"free\") + labs(x = \"State\", y = \"Count\", title = \"Case Count by Top State and Toxin Type\")\nby_tox_state\n\n\n\n\n\n\n\n#filtering data to only include top toxins\ntop_tox = botulism %&gt;% dplyr::filter(ToxinType == c(\"A\", \"B\", \"Unknown\"))\n\n#top toxin by year\nfreq_year_tox = ggplot(data = top_tox, aes(x = Year)) + geom_histogram(binwidth = 2, color = \"black\", fill = \"cyan\" )+ facet_wrap(~ToxinType) + labs(x = \"Year\", y = \"Count\", title = \"Frequency by Year and Toxin Type\")\nfreq_year_tox\n\n\n\n\n\n\n\n#filtering data to only include top contraction and toxin types\ntop_con = botulism %&gt;% dplyr::filter(BotType == c(\"Infant\", \"Foodborne\"), ToxinType == c(\"A\", \"B\", \"Unknown\"))\nby_tox_bot = ggplot(data = top_con, aes(x = BotType)) + geom_bar(color = \"black\", fill = \"grey\") + facet_wrap(~ToxinType) + labs(x = \"Contraction Type\", y = \"Count\", title = \"Frequency by Contraction Type and Toxin Type\")\nby_tox_bot\n\n\n\n\n\n\n\n\nBotulism cases went up around 1975, with A and B top toxins reflecting this increase. Contraction from an infant is the highest contraction type. By analyzing the top toxin and contraction types, toxin B happens most within infant contractions. We can hypothesize that B toxin is present in cases of infant botulism, and thus pass this toxin onto the non-infant cases reported in this dataset. On the opposite end, foodborne contractions have the highest unknown toxin. The top three toxins are seen consistently across the frequency of the top states (California, Alaska, Colorado, Oregon, Texas, Washington). All other toxins (not A, B, and unknown) only occur in one to two states."
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me",
    "section": "",
    "text": "My name is Amelia Tristan. I am looking to use my graduate degree in pharmacy/healthcare. I have a BS in Math with a minor in Computer Science from StMU. I am obsessed with cats and Sanrio. I am also currently unemployed so if anyone knows if their employers are hiring, please let me know. The job market is rough ):\n \nClick Here Here is a link to a scholarly article about cats and their outdoor roaming areas. Analysis shows male cats typically have a farther range of outdoor movement than female cats."
  },
  {
    "objectID": "coding-exercise/coding-exercise.html",
    "href": "coding-exercise/coding-exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Placeholder file for the future R coding exercise.\n\nlibrary(\"dplyr\")\nlibrary(\"tidyverse\")\nlibrary(\"ggplot2\")\nlibrary(\"dslabs\")\nlibrary(\"renv\")\n\n\n#look at help file for gapminder data\nhelp(gapminder)\n\nstarting httpd help server ... done\n\n#get an overview of data structure\nstr(gapminder)\n\n'data.frame':   10545 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  115.4 148.2 208 NA 59.9 ...\n $ life_expectancy : num  62.9 47.5 36 63 65.4 ...\n $ fertility       : num  6.19 7.65 7.32 4.43 3.11 4.55 4.82 3.45 2.7 5.57 ...\n $ population      : num  1636054 11124892 5270844 54681 20619075 ...\n $ gdp             : num  NA 1.38e+10 NA NA 1.08e+11 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 4 1 1 2 2 3 2 5 4 3 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 19 11 10 2 15 21 2 1 22 21 ...\n\n\n\n#get a summary of data\nsummary(gapminder)\n\n                country           year      infant_mortality life_expectancy\n Albania            :   57   Min.   :1960   Min.   :  1.50   Min.   :13.20  \n Algeria            :   57   1st Qu.:1974   1st Qu.: 16.00   1st Qu.:57.50  \n Angola             :   57   Median :1988   Median : 41.50   Median :67.54  \n Antigua and Barbuda:   57   Mean   :1988   Mean   : 55.31   Mean   :64.81  \n Argentina          :   57   3rd Qu.:2002   3rd Qu.: 85.10   3rd Qu.:73.00  \n Armenia            :   57   Max.   :2016   Max.   :276.90   Max.   :83.90  \n (Other)            :10203                  NA's   :1453                    \n   fertility       population             gdp               continent   \n Min.   :0.840   Min.   :3.124e+04   Min.   :4.040e+07   Africa  :2907  \n 1st Qu.:2.200   1st Qu.:1.333e+06   1st Qu.:1.846e+09   Americas:2052  \n Median :3.750   Median :5.009e+06   Median :7.794e+09   Asia    :2679  \n Mean   :4.084   Mean   :2.701e+07   Mean   :1.480e+11   Europe  :2223  \n 3rd Qu.:6.000   3rd Qu.:1.523e+07   3rd Qu.:5.540e+10   Oceania : 684  \n Max.   :9.220   Max.   :1.376e+09   Max.   :1.174e+13                  \n NA's   :187     NA's   :185         NA's   :2972                       \n             region    \n Western Asia   :1026  \n Eastern Africa : 912  \n Western Africa : 912  \n Caribbean      : 741  \n South America  : 684  \n Southern Europe: 684  \n (Other)        :5586  \n\n\n\n#determine the type of object gapminder is\nclass(gapminder)\n\n[1] \"data.frame\"\n\n\n\nafricadata = filter(gapminder, continent == 'Africa')\nhead(africadata)\n\n       country year infant_mortality life_expectancy fertility population\n1      Algeria 1960            148.2           47.50      7.65   11124892\n2       Angola 1960            208.0           35.98      7.32    5270844\n3        Benin 1960            186.9           38.29      6.28    2431620\n4     Botswana 1960            115.5           50.34      6.62     524029\n5 Burkina Faso 1960            161.3           35.21      6.29    4829291\n6      Burundi 1960            145.1           40.58      6.95    2786740\n          gdp continent          region\n1 13828152297    Africa Northern Africa\n2          NA    Africa   Middle Africa\n3   621797131    Africa  Western Africa\n4   124460933    Africa Southern Africa\n5   596612183    Africa  Western Africa\n6   341126765    Africa  Eastern Africa\n\n\n\nTo get overview of africadata\n\nstr(africadata)\n\n'data.frame':   2907 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n $ fertility       : num  7.65 7.32 6.28 6.62 6.29 6.95 5.65 6.89 5.84 6.25 ...\n $ population      : num  11124892 5270844 2431620 524029 4829291 ...\n $ gdp             : num  1.38e+10 NA 6.22e+08 1.24e+08 5.97e+08 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\n\n\n\nSummary of africadata\n\nsummary(africadata)\n\n         country          year      infant_mortality life_expectancy\n Algeria     :  57   Min.   :1960   Min.   : 11.40   Min.   :13.20  \n Angola      :  57   1st Qu.:1974   1st Qu.: 62.20   1st Qu.:48.23  \n Benin       :  57   Median :1988   Median : 93.40   Median :53.98  \n Botswana    :  57   Mean   :1988   Mean   : 95.12   Mean   :54.38  \n Burkina Faso:  57   3rd Qu.:2002   3rd Qu.:124.70   3rd Qu.:60.10  \n Burundi     :  57   Max.   :2016   Max.   :237.40   Max.   :77.60  \n (Other)     :2565                  NA's   :226                     \n   fertility       population             gdp               continent   \n Min.   :1.500   Min.   :    41538   Min.   :4.659e+07   Africa  :2907  \n 1st Qu.:5.160   1st Qu.:  1605232   1st Qu.:8.373e+08   Americas:   0  \n Median :6.160   Median :  5570982   Median :2.448e+09   Asia    :   0  \n Mean   :5.851   Mean   : 12235961   Mean   :9.346e+09   Europe  :   0  \n 3rd Qu.:6.860   3rd Qu.: 13888152   3rd Qu.:6.552e+09   Oceania :   0  \n Max.   :8.450   Max.   :182201962   Max.   :1.935e+11                  \n NA's   :51      NA's   :51          NA's   :637                        \n                       region   \n Eastern Africa           :912  \n Western Africa           :912  \n Middle Africa            :456  \n Northern Africa          :342  \n Southern Africa          :285  \n Australia and New Zealand:  0  \n (Other)                  :  0  \n\n\n\n\nInfant survival rate\n\ninfant_survival_rate = africadata %&gt;%\n  select(infant_mortality, life_expectancy)\nhead(infant_survival_rate)\n\n  infant_mortality life_expectancy\n1            148.2           47.50\n2            208.0           35.98\n3            186.9           38.29\n4            115.5           50.34\n5            161.3           35.21\n6            145.1           40.58\n\n\n\n\nStructure of infant survival\n\nstr(infant_survival_rate)\n\n'data.frame':   2907 obs. of  2 variables:\n $ infant_mortality: num  148 208 187 116 161 ...\n $ life_expectancy : num  47.5 36 38.3 50.3 35.2 ...\n\n\n\n\nsummary of infant survival\n\nsummary(infant_survival_rate)\n\n infant_mortality life_expectancy\n Min.   : 11.40   Min.   :13.20  \n 1st Qu.: 62.20   1st Qu.:48.23  \n Median : 93.40   Median :53.98  \n Mean   : 95.12   Mean   :54.38  \n 3rd Qu.:124.70   3rd Qu.:60.10  \n Max.   :237.40   Max.   :77.60  \n NA's   :226                     \n\n\n\n\nInfant mortality\n\nafrican_mortality = africadata %&gt;%\n  select(population, life_expectancy)\nhead(african_mortality)\n\n  population life_expectancy\n1   11124892           47.50\n2    5270844           35.98\n3    2431620           38.29\n4     524029           50.34\n5    4829291           35.21\n6    2786740           40.58\n\n\n\n\nAfrican mortality structure\n\nstr(african_mortality)\n\n'data.frame':   2907 obs. of  2 variables:\n $ population     : num  11124892 5270844 2431620 524029 4829291 ...\n $ life_expectancy: num  47.5 36 38.3 50.3 35.2 ...\n\n\n\n\nAfrican mortality summary\n\nsummary(african_mortality)\n\n   population        life_expectancy\n Min.   :    41538   Min.   :13.20  \n 1st Qu.:  1605232   1st Qu.:48.23  \n Median :  5570982   Median :53.98  \n Mean   : 12235961   Mean   :54.38  \n 3rd Qu.: 13888152   3rd Qu.:60.10  \n Max.   :182201962   Max.   :77.60  \n NA's   :51                         \n\n\n\nregression = lm(infant_survival_rate$life_expectancy ~ infant_survival_rate$infant_mortality)\nrsq &lt;- function(x, y) summary(lm(infant_survival_rate$life_expectancy ~ infant_survival_rate$infant_mortality))$r.squared\nr_square = round(rsq(obs, mod), 3)\n\ncoeff = round(summary(regression)$coefficients[2],3)\ny_int = round(summary(regression)$coefficients[1],3)\nplot(\n  infant_survival_rate$infant_mortality,\n  infant_survival_rate$life_expectancy,\n  main='African Life Expectancy \\n Infant Mortality Effect',\n  xlab='Infant Mortality',\n  ylab='Life Expectancy',\n   col='red', \n   bg='blue', \n   pch = 21,\n)\n\n\n\n\n\n\n\n\n\n\nLife expectancy as a function of population\n\nregression = lm(african_mortality$life_expectancy ~ african_mortality$population)\nrsq &lt;- function(x, y) summary(lm(african_mortality$life_expectancy ~ african_mortality$population))$r.squared\nr_square = round(rsq(obs, mod), 3)\n\ncoeff = round(summary(regression)$coefficients[2],9)\ny_int = round(summary(regression)$coefficients[1],3)\nplot(\n  african_mortality$population,\n  african_mortality$life_expectancy,\n  main='African Life Expectancy \\n Population Effect',\n  xlab='Population',\n  ylab='Life Expectancy',\n  col='pink', \n  bg='purple', \n  pch = 21,\n)\n\n\n\n\n\n\n\n\n\n\nMissing years for infant mortality\n\nmiss_inf_mort_rows = africadata %&gt;%\n  filter(is.na(infant_mortality))\nhead(miss_inf_mort_rows)\n\n            country year infant_mortality life_expectancy fertility population\n1        Cape Verde 1960               NA           50.12      6.89     202316\n2              Chad 1960               NA           40.95      6.25    3002596\n3          Djibouti 1960               NA           45.77      6.46      83636\n4 Equatorial Guinea 1960               NA           37.69      5.51     252115\n5           Eritrea 1960               NA           39.03      6.90    1407631\n6             Gabon 1960               NA           38.83      4.38     499189\n        gdp continent         region\n1        NA    Africa Western Africa\n2 750173439    Africa  Middle Africa\n3        NA    Africa Eastern Africa\n4        NA    Africa  Middle Africa\n5        NA    Africa Eastern Africa\n6 887289809    Africa  Middle Africa\n\n\n\n\nPerform year group by to identify missing year\n\nmiss_inf_mort_yrs = miss_inf_mort_rows %&gt;%\n  group_by(year) %&gt;%\n  count(infant_mortality)\nmiss_inf_mort_yrs\n\n# A tibble: 23 × 3\n# Groups:   year [23]\n    year infant_mortality     n\n   &lt;int&gt;            &lt;dbl&gt; &lt;int&gt;\n 1  1960               NA    10\n 2  1961               NA    17\n 3  1962               NA    16\n 4  1963               NA    16\n 5  1964               NA    15\n 6  1965               NA    14\n 7  1966               NA    13\n 8  1967               NA    11\n 9  1968               NA    11\n10  1969               NA     7\n# ℹ 13 more rows\n\n\n\n\nExtract only year 2000 from data\n\nafricadata2000 = filter(africadata, year == 2000)\nafricadata2000\n\n                    country year infant_mortality life_expectancy fertility\n1                   Algeria 2000             33.9            73.3      2.51\n2                    Angola 2000            128.3            52.3      6.84\n3                     Benin 2000             89.3            57.2      5.98\n4                  Botswana 2000             52.4            47.6      3.41\n5              Burkina Faso 2000             96.2            52.6      6.59\n6                   Burundi 2000             93.4            46.7      7.06\n7                  Cameroon 2000             91.9            54.3      5.62\n8                Cape Verde 2000             29.1            68.4      3.70\n9  Central African Republic 2000            113.6            45.3      5.45\n10                     Chad 2000            105.7            51.5      7.35\n11                  Comoros 2000             72.7            62.1      5.32\n12         Congo, Dem. Rep. 2000            107.4            54.3      7.09\n13              Congo, Rep. 2000             76.6            52.5      5.13\n14            Cote d'Ivoire 2000             99.5            52.0      5.38\n15                 Djibouti 2000             79.7            60.0      4.47\n16                    Egypt 2000             37.0            69.7      3.31\n17        Equatorial Guinea 2000            104.8            52.9      5.77\n18                  Eritrea 2000             58.3            37.6      5.94\n19                 Ethiopia 2000             89.5            52.1      6.53\n20                    Gabon 2000             55.6            59.3      4.60\n21                   Gambia 2000             63.3            63.6      5.92\n22                    Ghana 2000             64.9            60.0      4.67\n23                   Guinea 2000            103.1            54.2      5.94\n24            Guinea-Bissau 2000            106.9            52.8      5.85\n25                    Kenya 2000             66.5            55.6      5.01\n26                  Lesotho 2000             84.1            50.7      4.09\n27                  Liberia 2000            123.0            55.8      5.88\n28                    Libya 2000             24.2            74.8      3.05\n29               Madagascar 2000             69.7            59.1      5.55\n30                   Malawi 2000            103.5            45.4      6.25\n31                     Mali 2000            116.0            53.5      6.84\n32               Mauritania 2000             76.2            63.8      5.38\n33                Mauritius 2000             16.4            71.4      1.99\n34                  Morocco 2000             42.2            71.5      2.70\n35               Mozambique 2000            115.0            52.3      5.78\n36                  Namibia 2000             49.4            54.0      4.03\n37                    Niger 2000            101.1            52.4      7.73\n38                  Nigeria 2000            112.0            55.2      6.10\n39                   Rwanda 2000            109.2            49.2      5.90\n40                  Senegal 2000             68.5            59.7      5.56\n41               Seychelles 2000             12.3            70.9      2.15\n42             Sierra Leone 2000            143.3            51.5      5.92\n43             South Africa 2000             54.0            56.4      2.87\n44                    Sudan 2000             67.8            62.4      5.44\n45                Swaziland 2000             84.0            48.8      4.21\n46                 Tanzania 2000             80.3            54.3      5.69\n47                     Togo 2000             76.2            56.7      5.29\n48                  Tunisia 2000             26.3            75.0      2.11\n49                   Uganda 2000             90.0            49.1      6.87\n50                   Zambia 2000             97.6            44.8      6.07\n51                 Zimbabwe 2000             63.5            47.9      4.07\n   population          gdp continent          region\n1    31183658  54790058957    Africa Northern Africa\n2    15058638   9129180361    Africa   Middle Africa\n3     6949366   2254838685    Africa  Western Africa\n4     1736579   5632391130    Africa Southern Africa\n5    11607944   2610945549    Africa  Western Africa\n6     6767073    835334807    Africa  Eastern Africa\n7    15927713  10075040331    Africa   Middle Africa\n8      438737    539227053    Africa  Western Africa\n9     3726048    959413051    Africa   Middle Africa\n10    8343321   1385050964    Africa   Middle Africa\n11     547696    201900820    Africa  Eastern Africa\n12   48048664   4305797176    Africa   Middle Africa\n13    3109269   3219893817    Africa   Middle Africa\n14   16517948  10417006096    Africa  Western Africa\n15     722562    551230862    Africa  Eastern Africa\n16   68334905  99838540997    Africa Northern Africa\n17     530896   1254223037    Africa   Middle Africa\n18    3535156    633600000    Africa  Eastern Africa\n19   66443603   8179533779    Africa  Eastern Africa\n20    1231548   5067838984    Africa   Middle Africa\n21    1228863    786665264    Africa  Western Africa\n22   18824994   4977488790    Africa  Western Africa\n23    8799165   3112362568    Africa  Western Africa\n24    1315455    215455490    Africa  Western Africa\n25   31065820  12691278914    Africa  Eastern Africa\n26    1856225    745832990    Africa Southern Africa\n27    2891968    529064647    Africa  Western Africa\n28    5337264  33896600871    Africa Northern Africa\n29   15744811   3877575177    Africa  Eastern Africa\n30   11193230   1743506520    Africa  Eastern Africa\n31   11046926   2422469641    Africa  Western Africa\n32    2711421   1293653473    Africa  Western Africa\n33    1185143   4582562398    Africa  Eastern Africa\n34   28950553  37020609825    Africa Northern Africa\n35   18264536   4248747769    Africa  Eastern Africa\n36    1897953   3908501441    Africa Southern Africa\n37   11224523   1798365123    Africa  Western Africa\n38  122876723  45983449593    Africa  Western Africa\n39    8021875   1734921293    Africa  Eastern Africa\n40    9860578   4691828357    Africa  Western Africa\n41      81154    614879765    Africa  Eastern Africa\n42    4060709    635876870    Africa  Western Africa\n43   44896856 132877648091    Africa Southern Africa\n44   28079664  12366140066    Africa Northern Africa\n45    1063715   1524452437    Africa Southern Africa\n46   33991590  10185786171    Africa  Eastern Africa\n47    4874735   1294243543    Africa  Western Africa\n48    9699192  21473261837    Africa Northern Africa\n49   23757636   6193246632    Africa  Eastern Africa\n50   10585220   3237716325    Africa  Eastern Africa\n51   12499981   6689957610    Africa  Eastern Africa\n\n\n\n\nStructure of year 2000 data\n\nstr(africadata2000)\n\n'data.frame':   51 obs. of  9 variables:\n $ country         : Factor w/ 185 levels \"Albania\",\"Algeria\",..: 2 3 18 22 26 27 29 31 32 33 ...\n $ year            : int  2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\n $ infant_mortality: num  33.9 128.3 89.3 52.4 96.2 ...\n $ life_expectancy : num  73.3 52.3 57.2 47.6 52.6 46.7 54.3 68.4 45.3 51.5 ...\n $ fertility       : num  2.51 6.84 5.98 3.41 6.59 7.06 5.62 3.7 5.45 7.35 ...\n $ population      : num  31183658 15058638 6949366 1736579 11607944 ...\n $ gdp             : num  5.48e+10 9.13e+09 2.25e+09 5.63e+09 2.61e+09 ...\n $ continent       : Factor w/ 5 levels \"Africa\",\"Americas\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ region          : Factor w/ 22 levels \"Australia and New Zealand\",..: 11 10 20 17 20 5 10 20 10 10 ...\n\n\n\n\nSummary of yer 2000 data\n\nsummary(africadata2000)\n\n         country        year      infant_mortality life_expectancy\n Algeria     : 1   Min.   :2000   Min.   : 12.30   Min.   :37.60  \n Angola      : 1   1st Qu.:2000   1st Qu.: 60.80   1st Qu.:51.75  \n Benin       : 1   Median :2000   Median : 80.30   Median :54.30  \n Botswana    : 1   Mean   :2000   Mean   : 78.93   Mean   :56.36  \n Burkina Faso: 1   3rd Qu.:2000   3rd Qu.:103.30   3rd Qu.:60.00  \n Burundi     : 1   Max.   :2000   Max.   :143.30   Max.   :75.00  \n (Other)     :45                                                  \n   fertility       population             gdp               continent \n Min.   :1.990   Min.   :    81154   Min.   :2.019e+08   Africa  :51  \n 1st Qu.:4.150   1st Qu.:  2304687   1st Qu.:1.274e+09   Americas: 0  \n Median :5.550   Median :  8799165   Median :3.238e+09   Asia    : 0  \n Mean   :5.156   Mean   : 15659800   Mean   :1.155e+10   Europe  : 0  \n 3rd Qu.:5.960   3rd Qu.: 17391242   3rd Qu.:8.654e+09   Oceania : 0  \n Max.   :7.730   Max.   :122876723   Max.   :1.329e+11                \n                                                                      \n                       region  \n Eastern Africa           :16  \n Western Africa           :16  \n Middle Africa            : 8  \n Northern Africa          : 6  \n Southern Africa          : 5  \n Australia and New Zealand: 0  \n (Other)                  : 0  \n\n\n\n\nTo create a filter from dataset\n\nafrican_mortality2000 = africadata2000 %&gt;%\n  select(population, life_expectancy)\nhead(african_mortality2000)\n\n  population life_expectancy\n1   31183658            73.3\n2   15058638            52.3\n3    6949366            57.2\n4    1736579            47.6\n5   11607944            52.6\n6    6767073            46.7\n\n\n\n\nTo create another dataset\n\ninfant_survival_rate2000 = africadata2000 %&gt;%\n  select(infant_mortality, life_expectancy)\nhead(african_mortality2000)\n\n  population life_expectancy\n1   31183658            73.3\n2   15058638            52.3\n3    6949366            57.2\n4    1736579            47.6\n5   11607944            52.6\n6    6767073            46.7\n\n\n\n\ninfant mortality effect\n\nregression = lm(infant_survival_rate2000$life_expectancy ~ infant_survival_rate2000$infant_mortality)\nrsq &lt;- function(x, y) summary(lm(infant_survival_rate2000$life_expectancy ~ infant_survival_rate2000$infant_mortality))$r.squared\nr_square = round(rsq(obs, mod), 3)\n# summary(regression)$coefficients - keep to sanity check\ncoeff = round(summary(regression)$coefficients[2],3)\ny_int = round(summary(regression)$coefficients[1],3)\nplot(\n  infant_survival_rate2000$infant_mortality,\n  infant_survival_rate2000$life_expectancy,\n  main='African Life Expectancy \\n Infant Mortality Effect',\n  xlab='Infant Mortality',\n  ylab='Life Expectancy',\n   col='green', \n   bg='violet', \n   pch = 21,\n)\n\n\n\n\n\n\n\n\n\n\nPopulation effect\n\nregression = lm(african_mortality2000$life_expectancy ~ african_mortality2000$population)\nrsq &lt;- function(x, y) summary(lm(african_mortality2000$life_expectancy ~ african_mortality2000$population))$r.squared\nr_square = round(rsq(obs, mod), 3)\n# summary(regression)$coefficients - keep to sanity check\ncoeff = round(summary(regression)$coefficients[2],9)\ny_int = round(summary(regression)$coefficients[1],3)\nplot(\n  african_mortality2000$population,\n  african_mortality2000$life_expectancy,\n  main='African Life Expectancy \\n Population Effect',\n  xlab='Population',\n  ylab='Life Expectancy',\n  col='violet', \n  bg='red', \n  pch = 21,\n)\n\n\n\n\n\n\n\n\n\n\nSimple model fit\n\n\nLife expectancy to infant mortality\n\nfit1 = lm(life_expectancy ~ log(infant_mortality), data=infant_survival_rate2000)\nsummary(fit1)\n\n\nCall:\nlm(formula = life_expectancy ~ log(infant_mortality), data = infant_survival_rate2000)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-21.079  -3.068   1.157   3.511   8.998 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            106.765      6.681  15.981  &lt; 2e-16 ***\nlog(infant_mortality)  -11.827      1.556  -7.601 7.83e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.79 on 49 degrees of freedom\nMultiple R-squared:  0.5411,    Adjusted R-squared:  0.5317 \nF-statistic: 57.77 on 1 and 49 DF,  p-value: 7.827e-10\n\n\nThe R-squared is 0.5411, this means that 54% of life expectancy can be explained by infant mortality\n\n\nFit life expectancy to population\n\nfit2 = lm(life_expectancy ~ log(population), data=african_mortality2000)\nsummary(fit2)\n\n\nCall:\nlm(formula = life_expectancy ~ log(population), data = african_mortality2000)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.113  -4.809  -1.554   3.907  18.863 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      65.3243    12.5203   5.217 3.65e-06 ***\nlog(population)  -0.5711     0.7943  -0.719    0.476    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.502 on 49 degrees of freedom\nMultiple R-squared:  0.01044,   Adjusted R-squared:  -0.009755 \nF-statistic: 0.517 on 1 and 49 DF,  p-value: 0.4755\n\n\nThe R-squared is 0.01044 which means that 1% of population can be explained by life expentancy\n#Part 2 Amelia Tristan contributed to this exercise. Amelia used the mice_weight data set from dslabs.\n\n#open help page for mice_weights data and explore the data structure, class, and contents\nhelp(mice_weights) #help page\nstr(mice_weights) #structure\n\n'data.frame':   780 obs. of  7 variables:\n $ body_weight : num  27.6 23 28.7 32.6 28.6 ...\n $ bone_density: num  0.616 0.769 0.684 0.644 0.53 ...\n $ percent_fat : num  7.26 4.95 6.02 9.54 6.99 ...\n $ sex         : Factor w/ 2 levels \"F\",\"M\": 1 1 1 1 1 1 1 1 1 1 ...\n $ diet        : Factor w/ 2 levels \"chow\",\"hf\": 1 1 1 1 1 1 1 1 1 1 ...\n $ gen         : Factor w/ 5 levels \"4\",\"7\",\"8\",\"9\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ litter      : Factor w/ 2 levels \"1\",\"2\": 1 1 1 1 1 1 1 1 1 1 ...\n\nsummary(mice_weights) #contents\n\n  body_weight     bone_density     percent_fat     sex       diet     gen     \n Min.   :18.13   Min.   :0.2708   Min.   : 2.552   F:398   chow:394   4 : 97  \n 1st Qu.:28.09   1st Qu.:0.4888   1st Qu.: 5.566   M:382   hf  :386   7 :195  \n Median :32.98   Median :0.5643   Median : 8.276                      8 :193  \n Mean   :34.08   Mean   :0.5697   Mean   : 8.594                      9 : 97  \n 3rd Qu.:39.37   3rd Qu.:0.6373   3rd Qu.:10.926                      11:198  \n Max.   :65.15   Max.   :0.9980   Max.   :22.154                              \n                 NA's   :4        NA's   :4                                   \n litter \n 1:442  \n 2:338  \n        \n        \n        \n        \n        \n\nclass(mice_weights) #class\n\n[1] \"data.frame\"\n\nmice_weights\n\n    body_weight bone_density percent_fat sex diet gen litter\n1         27.60    0.6163850    7.255468   F chow   4      1\n2         23.03    0.7693496    4.951037   F chow   4      1\n3         28.72    0.6842564    6.020849   F chow   4      1\n4         32.57    0.6436947    9.536251   F chow   4      1\n5         28.61    0.5297713    6.987331   F chow   4      1\n6         28.16    0.5649217    6.767774   F chow   4      1\n7         29.16    0.6616988    7.984004   F chow   4      1\n8         26.48    0.5142428    7.934619   F chow   4      1\n9         28.53    0.5359991    6.922964   F chow   4      1\n10        30.89    0.7144773    7.312232   F chow   4      1\n11        19.16    0.6254541    4.511475   F chow   4      1\n12        21.84    0.5500263    5.938123   F chow   4      1\n13        23.70    0.7411152    4.428054   F chow   4      1\n14        22.08    0.5551574    5.920763   F chow   4      1\n15        21.32    0.6013931    5.359935   F chow   4      1\n16        25.05    0.5589034    5.729078   F chow   4      1\n17        27.64    0.5193837    8.336167   F chow   4      1\n18        30.19    0.6594427    8.425243   F chow   4      1\n19        31.86    0.5045634   10.646994   F chow   4      1\n20        22.92    0.6725300    4.586776   F chow   4      1\n21        24.84    0.5688549    7.619640   F chow   4      1\n22        25.52    0.6239913    4.150575   F chow   4      1\n23        25.15    0.4693777    8.426939   F chow   4      1\n24        29.51    0.4623166    9.647739   F chow   4      1\n25        24.81    0.6443711    5.227341   F chow   4      1\n26        23.57    0.4522034    4.479537   F chow   7      1\n27        27.93    0.5962986    5.832168   F chow   7      1\n28        30.08    0.4594603    7.257652   F chow   7      1\n29        25.47    0.3836840    5.931445   F chow   7      1\n30        19.20    0.3348764    3.575466   F chow   7      1\n31        28.53    0.4320692    8.794611   F chow   7      1\n32        30.36    0.6881334    4.133786   F chow   7      1\n33        26.38    0.4975044    4.289243   F chow   7      1\n34        26.55    0.4815078    6.529046   F chow   7      1\n35        23.77    0.4489765    6.933902   F chow   7      1\n36        38.41    0.5272563   11.522001   F chow   7      1\n37        32.96    0.4603540   10.076159   F chow   7      1\n38        26.02    0.6097897    4.061181   F chow   7      1\n39        24.21    0.5546149    5.690381   F chow   7      1\n40        28.62    0.5951879    5.869458   F chow   7      1\n41        27.96    0.4870451    8.013083   F chow   7      1\n42        30.49    0.5464572    7.843090   F chow   7      1\n43        22.28    0.4742473    4.298385   F chow   7      1\n44        35.19    0.6121465    7.472241   F chow   7      1\n45        28.34    0.4300713    7.057669   F chow   7      1\n46        25.73    0.4519949    5.965977   F chow   7      1\n47        27.93    0.5601777    5.787295   F chow   7      1\n48        29.49    0.4120593    8.860423   F chow   7      1\n49        35.73    0.4967115    8.539618   F chow   7      1\n50        26.77    0.6260935    3.180817   F chow   7      1\n51        23.26    0.4311890    4.258741   F chow   7      2\n52        34.06    0.6022277    8.362214   F chow   7      2\n53        29.71    0.5101918    7.670117   F chow   7      2\n54        28.15    0.5156155    7.922029   F chow   7      2\n55        30.47    0.3803084   10.669442   F chow   7      2\n56        23.28    0.5105845    5.456570   F chow   7      2\n57        25.89    0.4567418    6.378380   F chow   7      2\n58        20.13    0.5439827    3.057619   F chow   7      2\n59        31.75    0.3862048   11.149150   F chow   7      2\n60        25.57    0.3522040   10.045391   F chow   7      2\n61        23.34    0.5108176    5.054165   F chow   7      2\n62        21.01    0.5014798    3.403094   F chow   7      2\n63        23.57    0.5088575    4.946508   F chow   7      2\n64        31.19    0.4474425   10.014981   F chow   7      2\n65        23.14    0.4741755    5.973631   F chow   7      2\n66        25.74    0.4389420    6.937476   F chow   7      2\n67        32.05    0.4887393    9.354199   F chow   7      2\n68        22.97    0.5474371    5.052352   F chow   7      2\n69        30.84    0.4197261    9.683313   F chow   7      2\n70        29.69    0.5601070   14.645293   F chow   7      2\n71        18.71    0.4676987    2.854174   F chow   7      2\n72        26.81    0.5068910    6.423880   F chow   7      2\n73        24.80    0.6137272    5.607904   F chow   7      2\n74        25.90    0.4624997    6.198895   F chow   7      2\n75        34.08    0.5302091   11.345633   F chow   7      2\n76        27.96    0.3872410    9.427071   F chow   8      1\n77        25.98    0.7213100    3.333658   F chow   8      1\n78        32.31    0.4484742   12.328482   F chow   8      1\n79        37.12    0.6208335   13.631381   F chow   8      1\n80        25.96    0.6903609    3.123693   F chow   8      1\n81        27.19    0.5215449    5.064809   F chow   8      1\n82        29.74    0.5278612    7.568983   F chow   8      1\n83        26.37    0.3677261    8.181009   F chow   8      1\n84        35.08    0.5129342   10.531498   F chow   8      1\n85        24.92    0.4838253    6.454523   F chow   8      1\n86        28.40    0.5973696    6.217766   F chow   8      1\n87        48.96    0.6043429   13.629193   F chow   8      1\n88        34.78    0.4633798   10.220320   F chow   8      1\n89        31.78    0.4625339    8.571172   F chow   8      1\n90        28.65    0.5822841    4.753449   F chow   8      1\n91        20.86    0.4351211    4.207437   F chow   8      1\n92        28.49    0.6305969    3.837331   F chow   8      1\n93        29.48    0.5312687    5.829013   F chow   8      1\n94        27.14    0.4217566    8.571193   F chow   8      1\n95        27.08    0.5848237    5.515162   F chow   8      1\n96        22.57    0.5082938    3.836084   F chow   8      1\n97        27.70    0.5654720    5.099283   F chow   8      1\n98        26.15    0.5155432    6.295736   F chow   8      1\n99        25.18    0.5365844    5.369073   F chow   8      1\n100       27.33    0.7835293    4.814462   F chow   8      1\n101       28.26    0.4293765    7.246414   F chow   8      2\n102       31.27    0.5501901    9.023604   F chow   8      2\n103       33.10    0.4586336   13.589635   F chow   8      2\n104       35.45    0.4429900   11.793810   F chow   8      2\n105       22.12    0.3915315    4.567689   F chow   8      2\n106       35.87    0.4798999   11.582772   F chow   8      2\n107       30.63    0.6263737    4.759300   F chow   8      2\n108       30.96    0.6916406    6.362736   F chow   8      2\n109       23.11    0.4204155    4.804379   F chow   8      2\n110       34.16    0.5912600   10.809503   F chow   8      2\n111       18.28    0.3097717    5.037467   F chow   8      2\n112       29.12    0.4795378    8.999712   F chow   8      2\n113       18.78    0.3554516    4.214797   F chow   8      2\n114       26.15    0.3792791    9.900976   F chow   8      2\n115       21.14    0.4432730    5.748824   F chow   8      2\n116       24.63    0.4986398    6.303916   F chow   8      2\n117       28.87    0.7589253    4.725538   F chow   8      2\n118       24.24    0.5489208    4.529584   F chow   8      2\n119       26.74    0.6003606    4.604293   F chow   8      2\n120       28.75    0.4764352    9.265920   F chow   8      2\n121       29.87    0.8028513    5.615113   F chow   8      2\n122       26.32    0.5750478    4.525054   F chow   8      2\n123       21.52    0.5398341    4.324361   F chow   8      2\n124       19.42    0.3928275    4.060632   F chow   8      2\n125       20.55    0.5178370    4.607527   F chow   8      2\n126       28.04    0.4930090    6.890695   F chow   9      1\n127       33.96    0.7524616    4.850705   F chow   9      1\n128       24.85    0.4831268    4.717164   F chow   9      1\n129       24.84    0.4879846    5.160626   F chow   9      1\n130       23.80    0.6091361    4.037226   F chow   9      1\n131       21.84    0.5309287    2.839727   F chow   9      1\n132       27.21    0.4511757    3.324179   F chow   9      1\n133       22.93    0.4005840    5.136191   F chow   9      1\n134       39.52    0.5878198    9.960584   F chow   9      1\n135       26.88    0.5132615    5.432208   F chow   9      1\n136       22.89    0.6293626    3.252066   F chow   9      1\n137       25.90    0.4081161    7.424778   F chow   9      1\n138       25.69    0.4839708    5.825479   F chow   9      1\n139       26.12    0.5819887    5.070218   F chow   9      1\n140       32.12    0.7213044    6.755547   F chow   9      1\n141       24.22    0.5210252    4.522086   F chow   9      1\n142       28.52    0.4637815    7.475093   F chow   9      1\n143       31.21    0.6119007    6.001807   F chow   9      1\n144       24.28    0.6021625    3.937525   F chow   9      1\n145       36.71    0.6435668    9.838195   F chow   9      1\n146       37.18    0.4888361   11.475527   F chow   9      1\n147       22.73    0.5769124    3.807683   F chow   9      1\n148       34.73    0.5365265    9.803733   F chow   9      1\n149       27.27    0.5271607    6.993909   F chow   9      1\n150       24.71    0.6271212    3.773547   F chow   9      1\n151       23.88    0.4835726    4.439761   F chow  11      1\n152       27.07    0.4428226    7.955606   F chow  11      1\n153       22.37    0.7423121    2.765785   F chow  11      1\n154       26.00    0.7376226    3.587229   F chow  11      1\n155       29.14    0.5666247    6.378388   F chow  11      1\n156       27.75    0.6478794    5.019821   F chow  11      1\n157       21.35    0.4137302    6.008845   F chow  11      1\n158       22.63    0.5712425    3.313798   F chow  11      1\n159       30.65    0.4564834    8.969713   F chow  11      1\n160       23.62    0.3180739    6.648626   F chow  11      1\n161       26.19    0.4915647    7.237852   F chow  11      1\n162       33.39    0.5000142   11.017219   F chow  11      1\n163       39.79    0.5476406   14.276555   F chow  11      1\n164       31.06    0.4643144    9.150929   F chow  11      1\n165       35.97    0.6243706   10.439691   F chow  11      1\n166       37.47    0.4936475   11.421395   F chow  11      1\n167       25.35    0.3550908    9.158571   F chow  11      1\n168       33.87    0.5409362    9.894050   F chow  11      1\n169       29.25    0.6496376    7.471405   F chow  11      1\n170       25.98    0.5195610    6.550830   F chow  11      1\n171       21.02    0.4870278    4.103390   F chow  11      1\n172       32.50    0.4533731   10.247712   F chow  11      1\n173       23.50    0.4430728    5.231759   F chow  11      1\n174       35.17    0.5325864    6.575851   F chow  11      1\n175       29.28    0.4615445    8.393318   F chow  11      1\n176       27.99    0.4474149    7.837404   F chow  11      2\n177       24.35    0.5537441    4.889521   F chow  11      2\n178       30.69    0.4136720    8.402476   F chow  11      2\n179       27.85    0.5541371    6.143359   F chow  11      2\n180       25.18    0.6327898    4.533347   F chow  11      2\n181       22.81    0.6268461    3.698261   F chow  11      2\n182       32.33    0.4531320   10.596217   F chow  11      2\n183       29.38    0.6286016    6.034592   F chow  11      2\n184       38.77    0.5822433   11.653718   F chow  11      2\n185       33.88    0.5581700    9.753173   F chow  11      2\n186       30.09    0.5296013    7.809996   F chow  11      2\n187       23.42    0.7534986    3.814402   F chow  11      2\n188       26.71    0.6743639    4.865807   F chow  11      2\n189       32.50    0.5606744   10.005445   F chow  11      2\n190       29.53    0.7354373    6.211351   F chow  11      2\n191       28.69    0.5592686    6.326145   F chow  11      2\n192       28.92    0.6053767    6.731049   F chow  11      2\n193       35.68    0.5062775    9.982676   F chow  11      2\n194       27.13    0.5597812    5.460833   F chow  11      2\n195       40.87    0.5776726   12.562136   F chow  11      2\n196       28.70    0.5385624    5.535975   F chow  11      2\n197       28.31    0.7092915    3.735535   F chow  11      2\n198       29.48    0.4340300    8.349373   F chow  11      2\n199       21.97    0.3574281    6.047334   F chow  11      2\n200       24.18    0.5984447    3.999778   F chow  11      2\n201       46.96    0.8422064    9.347382   M chow   4      1\n202       31.13    0.6111998    6.975539   M chow   4      1\n203       37.23    0.6727096    7.576436   M chow   4      1\n204       27.01    0.5779432    5.445223   M chow   4      1\n205       36.13    0.7266646    5.942395   M chow   4      1\n206       31.08    0.7906264    4.659415   M chow   4      1\n207       44.92    0.7467643    8.760676   M chow   4      1\n208       34.12    0.8699289    5.193458   M chow   4      1\n209       34.87    0.9678787    4.488289   M chow   4      1\n210       28.69    0.8539888    4.115828   M chow   4      1\n211       34.77    0.5532298   10.756896   M chow   4      1\n212       37.66    0.6697955    7.996965   M chow   4      1\n213       39.75    0.6261557    9.590817   M chow   4      1\n214       35.23    0.6113271    6.486094   M chow   4      1\n215       45.57    0.5642464    9.741489   M chow   4      1\n216       37.04    0.6589865    7.425265   M chow   4      1\n217       37.35    0.4920937   10.522354   M chow   4      1\n218       35.02    0.5905549    8.436577   M chow   4      1\n219       28.67    0.6111161    5.654351   M chow   4      1\n220       39.95    0.9086910    5.630162   M chow   4      1\n221       39.04    0.7396796    8.751921   M chow   4      1\n222       32.96    0.6806490    5.971845   M chow   4      1\n223       31.51    0.8565056    4.922635   M chow   4      1\n224       31.09    0.5713592    6.430937   M chow   4      1\n225       37.19    0.6879323    8.325083   M chow   4      1\n226       33.93    0.5393047    4.809405   M chow   7      1\n227       36.13    0.5922721    4.672429   M chow   7      1\n228       33.79    0.5619828    4.526771   M chow   7      1\n229       31.85    0.6782195    2.759431   M chow   7      1\n230       29.33    0.5506595    4.275731   M chow   7      1\n231       46.87    0.5737750   12.855234   M chow   7      1\n232       40.87    0.4628998   15.120254   M chow   7      1\n233       42.52    0.6717359    7.683165   M chow   7      1\n234       36.47    0.5137134    9.478676   M chow   7      1\n235       39.53    0.6188471    7.683977   M chow   7      1\n236       32.44    0.5490999    4.839851   M chow   7      1\n237       27.78    0.5583725    2.832056   M chow   7      1\n238       31.56    0.7638562    3.265031   M chow   7      1\n239       34.90    0.5427565    6.367791   M chow   7      1\n240       30.88    0.5389778    5.554905   M chow   7      1\n241       37.32    0.7344123    5.729115   M chow   7      1\n242       36.54    0.5780414    6.848563   M chow   7      1\n243       44.84    0.7135176    6.624893   M chow   7      1\n244       29.30    0.7065738    3.241825   M chow   7      1\n245       45.83    0.5363258   11.535982   M chow   7      1\n246       27.87    0.6507932    3.093224   M chow   7      1\n247       36.95    0.6626018    5.982760   M chow   7      1\n248       31.96    0.6959673    2.595169   M chow   7      1\n249       27.82    0.5106059    4.548970   M chow   7      1\n250       33.09    0.5151109    5.703825   M chow   7      1\n251       31.80    0.5960780    6.135888   M chow   7      2\n252       28.55    0.5589921    4.819134   M chow   7      2\n253       34.85    0.7194783    4.032062   M chow   7      2\n254       30.05    0.5051342    4.852726   M chow   7      2\n255       34.92    0.6263658    6.863489   M chow   7      2\n256       34.83    0.5721964    5.744953   M chow   7      2\n257       39.81    0.4801612    8.947393   M chow   7      2\n258       32.66    0.6485466    4.496496   M chow   7      2\n259       27.94    0.6756025    3.203127   M chow   7      2\n260       30.63    0.5763775    6.158155   M chow   7      2\n261       32.78    0.8230245    2.669386   M chow   7      2\n262       39.08    0.5401460    8.526520   M chow   7      2\n263       31.51    0.7245127    4.583815   M chow   7      2\n264       28.49    0.5493321    4.290703   M chow   7      2\n265       32.78    0.7137379    2.552403   M chow   7      2\n266       31.05    0.5364699    4.943530   M chow   7      2\n267       30.36    0.6024085    3.729563   M chow   7      2\n268       31.52    0.5891442    4.773849   M chow   7      2\n269       30.11    0.6317645    3.514629   M chow   7      2\n270       27.09    0.6845312    3.143977   M chow   7      2\n271       39.36    0.6647998    7.399632   M chow   7      2\n272       33.76    0.6063618    5.142918   M chow   7      2\n273       34.23    0.7795570    2.979089   M chow   7      2\n274       29.58    0.6068908    4.016622   M chow   7      2\n275       33.85    0.7544970    4.791455   M chow   8      1\n276       32.24    0.6901971    3.646853   M chow   8      1\n277       38.79    0.5417177    8.493150   M chow   8      1\n278       33.29    0.7542064    3.555676   M chow   8      1\n279       31.25    0.6322389    4.101867   M chow   8      1\n280       41.41    0.5642601   10.445945   M chow   8      1\n281       47.88    0.7413012   10.123964   M chow   8      1\n282       29.87    0.6107160    3.730295   M chow   8      1\n283       38.96    0.6265078    8.128938   M chow   8      1\n284       32.93    0.6726292    3.189891   M chow   8      1\n285       54.19    0.5593191   14.193821   M chow   8      1\n286       38.43    0.5761923    8.726152   M chow   8      1\n287       41.16    0.5813417    9.652185   M chow   8      1\n288       41.22    0.5497555   10.427237   M chow   8      1\n289       41.76    0.6209241    8.628801   M chow   8      1\n290       35.01    0.6862062    7.590295   M chow   8      1\n291       31.77    0.5520464    6.910064   M chow   8      1\n292       45.69    0.5541671   12.227005   M chow   8      1\n293       43.69    0.5296401   10.417223   M chow   8      1\n294       42.00    0.6217057    9.205335   M chow   8      1\n295       35.91    0.8093043    4.171938   M chow   8      1\n296       30.07    0.6398623    5.720877   M chow   8      1\n297       31.65    0.4545715    6.879177   M chow   8      2\n298       29.13    0.4350061    6.909036   M chow   8      2\n299       32.75    0.7255540    5.227388   M chow   8      2\n300       37.83    0.6263384    8.774351   M chow   8      2\n301       30.21    0.5754862    4.220553   M chow   8      2\n302       30.30    0.5400077    5.900125   M chow   8      2\n303       30.82    0.5156424    3.525433   M chow   8      2\n304       35.24    0.5566914    7.600781   M chow   8      2\n305       28.23    0.5081906    5.558316   M chow   8      2\n306       23.62    0.3977376    5.176057   M chow   8      2\n307       35.76    0.6070748    9.216941   M chow   8      2\n308       31.54    0.4622658    9.143431   M chow   8      2\n309       43.66    0.5472091   11.751905   M chow   8      2\n310       34.12    0.4162632   10.461449   M chow   8      2\n311       31.16    0.4786680    7.173990   M chow   8      2\n312       26.38    0.4966435    4.429531   M chow   8      2\n313       34.39    0.5971903    6.970577   M chow   8      2\n314       39.86    0.5961614    8.718027   M chow   8      2\n315       46.33    0.5875316    9.771089   M chow   8      2\n316       31.25    0.4641367    8.302584   M chow   8      2\n317       29.35    0.6126289    4.629298   M chow   8      2\n318       39.18    0.6395900    8.774351   M chow   8      2\n319       24.01    0.5013250    4.126429   M chow   8      2\n320       40.89    0.6344959    8.617172   M chow   8      2\n321       30.43    0.6368130    4.705845   M chow   9      1\n322       35.48    0.6365770    5.617374   M chow   9      1\n323       45.62    0.8291159    6.841993   M chow   9      1\n324       36.91    0.6709085    6.198882   M chow   9      1\n325       40.27    0.6672788    6.472033   M chow   9      1\n326       35.48    0.5921929    6.432803   M chow   9      1\n327       28.69    0.5443375    4.555785   M chow   9      1\n328       41.46    0.6008759    8.436475   M chow   9      1\n329       35.32    0.5830557    6.788699   M chow   9      1\n330       47.25    0.8104933    6.878817   M chow   9      1\n331       36.77    0.6590361    7.355450   M chow   9      1\n332       33.04    0.6267148    4.464093   M chow   9      1\n333       27.55    0.6282138    3.327790   M chow   9      1\n334       48.85    0.5154748   14.494018   M chow   9      1\n335       24.23    0.6025328    2.912740   M chow   9      1\n336       33.99    0.5784766    6.607907   M chow   9      1\n337       28.91    0.5394424    4.271345   M chow   9      1\n338       36.60    0.8118818    3.433447   M chow   9      1\n339       43.76    0.5978313    8.137291   M chow   9      1\n340       39.36    0.5934049    8.638252   M chow   9      1\n341       33.96    0.7958171    4.756177   M chow   9      1\n342       27.47    0.5976982    4.279392   M chow   9      1\n343       46.53    0.8421400    9.272718   M chow   9      1\n344       32.86    0.4454776    9.105080   M chow   9      1\n345       30.54    0.6119286    5.083053   M chow  11      1\n346       42.03    0.6402051    8.189572   M chow  11      1\n347       34.49    0.6628376    4.254799   M chow  11      1\n348       28.57    0.5141444    5.119700   M chow  11      1\n349       29.93    0.6006891    3.804286   M chow  11      1\n350       32.29    0.7182986    3.163480   M chow  11      1\n351       28.43    0.4871676    5.550270   M chow  11      1\n352       34.52    0.7744269    4.057324   M chow  11      1\n353       27.69    0.7349178    3.519013   M chow  11      1\n354       43.11    0.6263009    9.986434   M chow  11      1\n355       46.61    0.6995050    8.047594   M chow  11      1\n356       35.28    0.8049064    4.075271   M chow  11      1\n357       36.73    0.5016227    8.616300   M chow  11      1\n358       33.60    0.7039518    5.863880   M chow  11      1\n359       44.01    0.6024615    8.497547   M chow  11      1\n360       35.30    0.5885006    7.692371   M chow  11      1\n361       44.85    0.6043670    8.943331   M chow  11      1\n362       48.91    0.6356125    9.857012   M chow  11      1\n363       35.86    0.5722899    8.408468   M chow  11      1\n364       27.19    0.5156705    5.243598   M chow  11      1\n365       34.28    0.5535636    7.874634   M chow  11      1\n366       34.48    0.7115525    4.539026   M chow  11      1\n367       40.55    0.5954592    9.568270   M chow  11      1\n368       54.73    0.8321430    9.926929   M chow  11      1\n369       36.86    0.5746424    7.919502   M chow  11      1\n370       31.86    0.6504287    3.982150   M chow  11      2\n371       33.82    0.6990643    4.675906   M chow  11      2\n372       27.99    0.6334171    3.975214   M chow  11      2\n373       44.43    0.5947148    9.580098   M chow  11      2\n374       33.76    0.7131673    4.720389   M chow  11      2\n375       30.51    0.5749106    5.098776   M chow  11      2\n376       44.46    0.4440194   11.796323   M chow  11      2\n377       37.78    0.6129066   10.069350   M chow  11      2\n378       30.99    0.4270255    9.080844   M chow  11      2\n379       35.34    0.8000546    5.099123   M chow  11      2\n380       38.28    0.9735840    4.282900   M chow  11      2\n381       29.82    0.6758081    4.487535   M chow  11      2\n382       32.07    0.7379309    3.652785   M chow  11      2\n383       43.34    0.9980361    3.997422   M chow  11      2\n384       37.19    0.7344816    5.014806   M chow  11      2\n385       32.86    0.7004923    5.160785   M chow  11      2\n386       41.60    0.6199465    6.956482   M chow  11      2\n387       32.99    0.6703653    5.667645   M chow  11      2\n388       40.63    0.5659741    8.761349   M chow  11      2\n389       37.54    0.5718262    8.429571   M chow  11      2\n390       32.33    0.5774217    5.028275   M chow  11      2\n391       35.04    0.7390307    4.220666   M chow  11      2\n392       29.15    0.5311730    4.755384   M chow  11      2\n393       27.59    0.4301865    6.895794   M chow  11      2\n394       34.78    0.7961320    4.377588   M chow  11      2\n395       36.78    0.4791915   14.972857   F   hf   4      2\n396       37.65    0.5426322   14.920081   F   hf   4      2\n397       24.37    0.8518800    5.090817   F   hf   4      2\n398       21.51    0.5108683    6.222426   F   hf   4      2\n399       39.35    0.4558855   13.569728   F   hf   4      2\n400       37.57    0.4737981   14.097857   F   hf   4      2\n401       31.39    0.4482576    9.176294   F   hf   4      2\n402       49.73    0.5691473   18.615009   F   hf   4      2\n403       21.45    0.6752360    4.392884   F   hf   4      2\n404       27.47    0.3685138   10.889632   F   hf   4      2\n405       24.05    0.4888014    7.868612   F   hf   4      2\n406       23.70    0.4522095    8.062532   F   hf   4      2\n407       30.40    0.5143597    9.393370   F   hf   4      2\n408       28.72    0.6426573    6.013154   F   hf   4      2\n409       40.79    0.5404014   13.479010   F   hf   4      2\n410       40.57    0.4917382   14.499016   F   hf   4      2\n411       40.13    0.4956310   14.356157   F   hf   4      2\n412       26.87    0.5134021    8.054986   F   hf   4      2\n413       31.51    0.5156333   10.878812   F   hf   4      2\n414       32.44    0.4503678   11.428721   F   hf   4      2\n415       26.52    0.5050897   14.575981   F   hf   4      2\n416       32.18    0.4616167   13.721851   F   hf   4      2\n417       32.52    0.4178651   14.077239   F   hf   4      2\n418       26.49    0.3963328    9.862208   F   hf   4      2\n419       34.89    0.4540729   11.516761   F   hf   4      2\n420       35.31    0.4309373   11.048741   F   hf   7      1\n421       25.46    0.3913615    8.574490   F   hf   7      1\n422       38.31    0.3864866   16.187637   F   hf   7      1\n423       33.00    0.4106852    8.556639   F   hf   7      1\n424       29.91    0.6682250   16.046507   F   hf   7      1\n425       33.33    0.3092547   11.517836   F   hf   7      1\n426       40.19    0.5099173   17.292823   F   hf   7      1\n427       22.11    0.5407052    4.060462   F   hf   7      1\n428       24.00    0.3827372    6.650978   F   hf   7      1\n429       36.17    0.6343537   13.679263   F   hf   7      1\n430       33.22    0.5960025    9.842103   F   hf   7      1\n431       23.27    0.5515580    4.412961   F   hf   7      1\n432       24.16    0.4531441    6.700706   F   hf   7      1\n433       35.44    0.5363373   14.452939   F   hf   7      1\n434       29.94    0.4306204    9.066970   F   hf   7      1\n435       26.85    0.5081906    5.568120   F   hf   7      1\n436       28.64    0.5417305    7.481138   F   hf   7      1\n437       31.07    0.4180159   12.597300   F   hf   7      1\n438       34.79    0.5524192   12.744235   F   hf   7      1\n439       33.27    0.2707646   14.273753   F   hf   7      1\n440       22.63    0.5011213    4.649181   F   hf   7      1\n441       32.51    0.5116109   12.256458   F   hf   7      1\n442       38.89    0.6214238    9.242202   F   hf   7      1\n443       26.33    0.5016250    5.410671   F   hf   7      1\n444       28.05    0.3857903    9.784692   F   hf   7      2\n445       29.11    0.6355164    5.328522   F   hf   7      2\n446       35.12    0.4831941   11.815044   F   hf   7      2\n447       18.13    0.5537521    3.434569   F   hf   7      2\n448       36.39    0.5090197    9.149866   F   hf   7      2\n449       28.67    0.5380232   11.080986   F   hf   7      2\n450       26.02    0.4060777    9.014889   F   hf   7      2\n451       28.10    0.5108064    8.236163   F   hf   7      2\n452       27.84    0.5457396    7.401222   F   hf   7      2\n453       31.70    0.5771756    9.938308   F   hf   7      2\n454       26.47    0.4595108    8.495810   F   hf   7      2\n455       41.61    0.6397208   13.600228   F   hf   7      2\n456       30.42    0.4518817   10.202179   F   hf   7      2\n457       30.26    0.4601013   10.910607   F   hf   7      2\n458       20.46    0.4893250    3.695797   F   hf   7      2\n459       25.35    0.4675599    6.657242   F   hf   7      2\n460       28.56    0.4103118    8.742364   F   hf   7      2\n461       30.88    0.4327551   11.230833   F   hf   7      2\n462       23.06    0.4839239    5.220665   F   hf   7      2\n463       25.26    0.4501808    7.180970   F   hf   7      2\n464       30.50    0.5469306    8.226432   F   hf   7      2\n465       40.89    0.4768723   16.687755   F   hf   7      2\n466       37.82    0.6133873   12.554644   F   hf   7      2\n467       27.02    0.6636518    5.921590   F   hf   7      2\n468       28.96    0.3953194   12.118643   F   hf   8      1\n469       35.66    0.6972905    9.967599   F   hf   8      1\n470       26.98    0.5161154    8.111887   F   hf   8      1\n471       38.15    0.4562186   15.911508   F   hf   8      1\n472       38.65    0.4092699   14.861288   F   hf   8      1\n473       36.97    0.4672348   13.131061   F   hf   8      1\n474       28.63    0.5806423    8.209806   F   hf   8      1\n475       31.44    0.4684914    9.212065   F   hf   8      1\n476       30.66    0.4004696   10.903834   F   hf   8      1\n477       52.63    0.5302577   19.836967   F   hf   8      1\n478       33.67    0.4537242   12.526658   F   hf   8      1\n479       28.01    0.5852470    7.405188   F   hf   8      1\n480       30.69    0.4839498   11.214925   F   hf   8      1\n481       45.18    0.6327316   12.345783   F   hf   8      1\n482       30.89    0.5006004    9.488100   F   hf   8      1\n483       21.15    0.4766194    6.700704   F   hf   8      1\n484       23.16    0.5750262    4.048249   F   hf   8      1\n485       25.96    0.5131296    6.208077   F   hf   8      1\n486       24.16    0.4159714    6.152457   F   hf   8      1\n487       22.01    0.5901843    4.190406   F   hf   8      1\n488       30.24    0.4979960    9.461528   F   hf   8      1\n489       26.78    0.5068407    7.147674   F   hf   8      1\n490       34.51    0.6245325   10.821784   F   hf   8      1\n491       31.25    0.4751889   13.373124   F   hf   8      1\n492       42.15    0.5459153   18.510404   F   hf   8      1\n493       29.45    0.4203396   13.144116   F   hf   8      2\n494       20.75    0.4293577    7.703506   F   hf   8      2\n495       21.98    0.5718934    5.117442   F   hf   8      2\n496       29.37    0.6769082    8.479381   F   hf   8      2\n497       29.67    0.5684464    9.764790   F   hf   8      2\n498       29.17    0.5318935   10.046018   F   hf   8      2\n499       26.78    0.4510068    9.774414   F   hf   8      2\n500       32.06    0.4430148   14.023962   F   hf   8      2\n501       40.13    0.5633591   17.090807   F   hf   8      2\n502       29.31    0.5125794   12.289222   F   hf   8      2\n503       27.58    0.4662467    9.210958   F   hf   8      2\n504       43.05    0.7014378   15.874402   F   hf   8      2\n505       35.68    0.5792697   14.933506   F   hf   8      2\n506       30.12    0.4720496   11.084323   F   hf   8      2\n507       25.17    0.4998734    5.428394   F   hf   8      2\n508       21.78    0.4416614    5.282831   F   hf   8      2\n509       26.63    0.4806286    8.844649   F   hf   8      2\n510       24.67    0.3588992   10.118731   F   hf   8      2\n511       24.03    0.3620492   10.892672   F   hf   8      2\n512       19.11    0.3502319    6.183302   F   hf   8      2\n513       40.22    0.5122950   17.358619   F   hf   8      2\n514       30.03    0.5850403    8.244955   F   hf   8      2\n515       37.98           NA          NA   F   hf   8      2\n516       39.62    0.5343270   16.410095   F   hf   8      2\n517       27.88    0.4339696   14.759346   F   hf   8      2\n518       48.45    0.5683520   16.761690   F   hf   9      1\n519       31.03    0.4326682   10.332736   F   hf   9      1\n520       24.20    0.5803786    5.657671   F   hf   9      1\n521       26.40    0.6481146    6.886099   F   hf   9      1\n522       33.80    0.4430944   14.049729   F   hf   9      1\n523       30.18    0.5189120    7.951201   F   hf   9      1\n524       33.74    0.5183169   13.664379   F   hf   9      1\n525       34.84    0.3795786    9.625234   F   hf   9      1\n526       26.76    0.4403390    9.008581   F   hf   9      1\n527       26.81    0.4958401   12.447572   F   hf   9      1\n528       34.74    0.4440180   13.232726   F   hf   9      1\n529       43.38    0.5638588   18.061429   F   hf   9      1\n530       30.91    0.6264599    7.780825   F   hf   9      1\n531       32.61    0.2960922   14.877347   F   hf   9      1\n532       29.90    0.6098461    6.262313   F   hf   9      1\n533       27.12    0.5680498    8.041453   F   hf   9      1\n534       53.09    0.8144595   15.271819   F   hf   9      1\n535       31.97    0.5168427   11.133854   F   hf   9      1\n536       28.69    0.4924638    7.719934   F   hf   9      1\n537       29.94    0.3869557   10.960064   F   hf   9      1\n538       24.66    0.5928887    5.078171   F   hf   9      1\n539       27.55    0.4625283    8.627423   F   hf   9      1\n540       22.58    0.4814556    5.858490   F   hf   9      1\n541       65.15    0.6271248   22.153527   F   hf   9      1\n542       34.47    0.5030213   13.313508   F   hf   9      1\n543       35.71    0.6219957   10.249940   F   hf  11      1\n544       37.07    0.5074155   13.423188   F   hf  11      1\n545       27.80    0.6944491    5.182845   F   hf  11      1\n546       23.92    0.3665140   10.916940   F   hf  11      1\n547       41.75    0.5988272   15.472837   F   hf  11      1\n548       36.91    0.3935475   15.300186   F   hf  11      1\n549       28.38    0.3982388    8.055351   F   hf  11      1\n550       27.87    0.3913637    9.799300   F   hf  11      1\n551       41.26    0.5913349   15.522474   F   hf  11      1\n552       21.14    0.4891245    4.480588   F   hf  11      1\n553       37.98    0.5236159   15.097764   F   hf  11      1\n554       24.57    0.3160615    8.015289   F   hf  11      1\n555       33.19    0.4088551   11.961765   F   hf  11      1\n556       40.42    0.4574383   15.386360   F   hf  11      1\n557       29.56    0.4133142    9.150530   F   hf  11      1\n558       33.26    0.5069697   11.381120   F   hf  11      1\n559       37.99    0.5305946   13.130824   F   hf  11      1\n560       37.81    0.6900764   12.189262   F   hf  11      1\n561       32.17    0.4690800   13.469284   F   hf  11      1\n562       35.36    0.3509880    8.901083   F   hf  11      1\n563       34.03    0.6797212   11.085896   F   hf  11      1\n564       24.12    0.5258425    5.347615   F   hf  11      1\n565       27.20    0.6609721    5.830723   F   hf  11      1\n566       25.50    0.3034046   12.083395   F   hf  11      1\n567       36.37    0.4004156   16.127476   F   hf  11      1\n568       29.13    0.3711754   10.088360   F   hf  11      2\n569       29.63    0.3723204   10.545365   F   hf  11      2\n570       35.84    0.6632287    9.134248   F   hf  11      2\n571       49.89    0.4187838   15.836615   F   hf  11      2\n572       44.36    0.4748529   16.344485   F   hf  11      2\n573       31.76    0.6403306    7.105132   F   hf  11      2\n574       37.47    0.6217026    9.617248   F   hf  11      2\n575       25.22    0.4846312    5.910321   F   hf  11      2\n576       36.19    0.4603838   14.483904   F   hf  11      2\n577       24.19    0.5359504    5.957439   F   hf  11      2\n578       35.15    0.4585576   10.287642   F   hf  11      2\n579       48.37    0.5007017   13.809198   F   hf  11      2\n580       32.10    0.5566545    8.489143   F   hf  11      2\n581       28.77    0.4672989    7.218651   F   hf  11      2\n582       37.47    0.5458276    9.903274   F   hf  11      2\n583       42.90    0.6392744   12.318086   F   hf  11      2\n584       24.90    0.4918541    5.689916   F   hf  11      2\n585       30.32    0.4805390    9.994582   F   hf  11      2\n586       33.13    0.4449042   11.527886   F   hf  11      2\n587       20.72    0.4780603    5.444732   F   hf  11      2\n588       35.81    0.4813184    9.917155   F   hf  11      2\n589       30.42    0.4562834   10.475403   F   hf  11      2\n590       34.53    0.4136204   14.116862   F   hf  11      2\n591       36.63    0.4270131   14.505307   F   hf  11      2\n592       32.79    0.5015317   13.395970   F   hf  11      2\n593       33.67    0.5271769    9.627342   M   hf   4      2\n594       37.95    0.4720846   11.743011   M   hf   4      2\n595       41.67    0.5781099   12.547977   M   hf   4      2\n596       35.96    0.5169185    9.110549   M   hf   4      2\n597       45.50    0.4559956   13.692128   M   hf   4      2\n598       31.50    0.6237731    6.852263   M   hf   4      2\n599       49.21    0.5827445   12.604396   M   hf   4      2\n600       42.80    0.6679169    8.667087   M   hf   4      2\n601       40.60    0.5944620   11.347651   M   hf   4      2\n602       40.98    0.4890448   10.742711   M   hf   4      2\n603       46.33    0.6856548   11.759477   M   hf   4      2\n604       42.95    0.6383454    8.776546   M   hf   4      2\n605       48.61    0.5366447   12.051097   M   hf   4      2\n606       45.56    0.5928320   10.525746   M   hf   4      2\n607       46.84    0.6757206   12.588910   M   hf   4      2\n608       53.89    0.5781559   14.369164   M   hf   4      2\n609       41.89    0.5103366   15.143179   M   hf   4      2\n610       45.46    0.6367204   12.795827   M   hf   4      2\n611       33.70    0.4946576    8.563304   M   hf   4      2\n612       45.99    0.6454203   17.891309   M   hf   4      2\n613       46.89    0.6331602    9.809824   M   hf   4      2\n614       42.44    0.5046799   11.198073   M   hf   4      2\n615       32.33    0.5651886    7.617587   M   hf   7      1\n616       52.19    0.5999931   15.240861   M   hf   7      1\n617       38.84    0.5795426   11.174218   M   hf   7      1\n618       49.03    0.4552080   12.250519   M   hf   7      1\n619       58.01    0.7384632   17.620789   M   hf   7      1\n620       46.15    0.7069544   10.038533   M   hf   7      1\n621       43.56    0.5861579   12.018963   M   hf   7      1\n622       41.45    0.5473085   11.078114   M   hf   7      1\n623       36.07    0.6916024    8.851358   M   hf   7      1\n624       37.89           NA          NA   M   hf   7      1\n625       48.04    0.6462911   12.916183   M   hf   7      1\n626       30.67    0.5311443    8.695084   M   hf   7      1\n627       41.21    0.7941369    8.945946   M   hf   7      1\n628       42.94    0.8115798    9.593869   M   hf   7      1\n629       41.20    0.4191356   12.237421   M   hf   7      1\n630       51.42    0.6072221   12.216469   M   hf   7      1\n631       30.28    0.5830653    4.684610   M   hf   7      1\n632       38.09    0.6842436    8.633210   M   hf   7      1\n633       46.91    0.5557420   10.676100   M   hf   7      1\n634       41.08    0.7089663   10.718980   M   hf   7      1\n635       43.19    0.6959646    9.853061   M   hf   7      1\n636       47.08    0.7145670   12.608324   M   hf   7      1\n637       24.19    0.4780566    4.715495   M   hf   7      1\n638       34.23    0.6011765    7.005428   M   hf   7      1\n639       29.65    0.4553158    8.839014   M   hf   7      2\n640       40.87    0.5578455    5.368700   M   hf   7      2\n641       35.29    0.7538916    5.924237   M   hf   7      2\n642       39.73    0.5288558    8.546405   M   hf   7      2\n643       34.61    0.6103602    4.085000   M   hf   7      2\n644       39.21    0.7258755    5.777293   M   hf   7      2\n645       30.80    0.6024498    4.563982   M   hf   7      2\n646       46.58    0.6308865   14.912887   M   hf   7      2\n647       43.37    0.5312434   13.314832   M   hf   7      2\n648       35.48    0.6539562    5.113069   M   hf   7      2\n649       49.66    0.4448160   16.524851   M   hf   7      2\n650       43.21           NA          NA   M   hf   7      2\n651       51.87    0.6863687   19.490546   M   hf   7      2\n652       47.72    0.6350715   14.182063   M   hf   7      2\n653       36.95    0.5923002   12.828634   M   hf   7      2\n654       56.97    0.7630653   12.073297   M   hf   7      2\n655       44.56    0.5310632   12.825957   M   hf   7      2\n656       49.32    0.6793050   15.961174   M   hf   7      2\n657       43.57    0.5745345   12.811710   M   hf   7      2\n658       41.43    0.5819637   11.374868   M   hf   7      2\n659       51.23    0.4992553   13.855205   M   hf   7      2\n660       52.49    0.6480445   14.260694   M   hf   7      2\n661       34.64    0.5638451    7.851969   M   hf   7      2\n662       39.05    0.6565215   11.504441   M   hf   7      2\n663       38.79    0.5848405    9.668564   M   hf   8      1\n664       59.48    0.6462378   17.414257   M   hf   8      1\n665       44.16    0.4354087   14.404029   M   hf   8      1\n666       42.08    0.5218190   16.005604   M   hf   8      1\n667       43.09    0.5705899   13.123158   M   hf   8      1\n668       58.64    0.7091164   20.011494   M   hf   8      1\n669       33.19    0.5748064    8.409829   M   hf   8      1\n670       55.62    0.6422794   13.642035   M   hf   8      1\n671       40.37    0.5063113   14.644191   M   hf   8      1\n672       47.11    0.7054494   13.594880   M   hf   8      1\n673       57.08    0.6216992   19.906432   M   hf   8      1\n674       39.41    0.5965378   10.675004   M   hf   8      1\n675       34.58    0.5419469    8.334256   M   hf   8      1\n676       34.91    0.5305891    9.452314   M   hf   8      1\n677       61.15    0.6804202   14.188766   M   hf   8      1\n678       37.84    0.6448059    7.412838   M   hf   8      1\n679       43.56    0.6535431   10.037169   M   hf   8      1\n680       47.62    0.6372416   10.710193   M   hf   8      1\n681       46.73    0.5064043   12.892049   M   hf   8      1\n682       31.47    0.6904290    6.047852   M   hf   8      1\n683       45.28    0.5492885   10.559688   M   hf   8      1\n684       39.44    0.7350714    7.930600   M   hf   8      1\n685       32.01    0.5447388    4.399978   M   hf   8      1\n686       43.75    0.6294615   16.125565   M   hf   8      1\n687       42.16    0.5968079   11.259410   M   hf   8      1\n688       37.85    0.5810146    8.249245   M   hf   8      2\n689       32.78    0.5999964    5.945865   M   hf   8      2\n690       57.84    0.6373229   18.148941   M   hf   8      2\n691       39.22    0.4035991   12.060200   M   hf   8      2\n692       39.24    0.5829904   14.337305   M   hf   8      2\n693       39.62    0.5786735   11.671334   M   hf   8      2\n694       29.68    0.5625437    9.271594   M   hf   8      2\n695       40.85    0.5670734   10.003199   M   hf   8      2\n696       39.16    0.5528640   13.093305   M   hf   8      2\n697       35.98    0.7004704   10.454399   M   hf   8      2\n698       49.38    0.5835433   14.062127   M   hf   8      2\n699       40.32    0.5482792   14.816044   M   hf   8      2\n700       39.45    0.6225802   11.673302   M   hf   8      2\n701       40.26    0.6049711   10.953615   M   hf   8      2\n702       36.10    0.5639987    7.189852   M   hf   8      2\n703       30.25    0.5243011    6.782778   M   hf   8      2\n704       41.78    0.4805120   11.380579   M   hf   8      2\n705       43.65    0.6726879   14.206064   M   hf   8      2\n706       42.13    0.7591266   13.305264   M   hf   8      2\n707       47.19    0.8103861   12.182219   M   hf   8      2\n708       39.88    0.5815707   12.189806   M   hf   8      2\n709       36.98    0.5701659   11.700699   M   hf   8      2\n710       35.63    0.6604770    7.821327   M   hf   9      1\n711       43.75    0.7463843   10.102200   M   hf   9      1\n712       38.76    0.8092204   16.266865   M   hf   9      1\n713       36.10    0.5819288    8.477329   M   hf   9      1\n714       40.92    0.5715493   10.530162   M   hf   9      1\n715       37.53    0.6304227    8.435664   M   hf   9      1\n716       47.18    0.4884376   12.457874   M   hf   9      1\n717       44.70    0.8520423   10.871031   M   hf   9      1\n718       48.29    0.5853378   13.093814   M   hf   9      1\n719       43.03    0.6647549   10.538212   M   hf   9      1\n720       33.02    0.4692096    8.588812   M   hf   9      1\n721       39.73    0.6384918    6.817203   M   hf   9      1\n722       43.86    0.6743911   10.185073   M   hf   9      1\n723       50.96    0.7525395   10.715858   M   hf   9      1\n724       29.41    0.6151207    6.132404   M   hf   9      1\n725       46.49    0.7214477   12.633160   M   hf   9      1\n726       38.06    0.7693789    8.460162   M   hf   9      1\n727       37.34    0.7136857    4.712712   M   hf   9      1\n728       33.45    0.6010833    6.906610   M   hf   9      1\n729       30.58    0.4935884    7.862133   M   hf   9      1\n730       40.45    0.6624970    6.587354   M   hf   9      1\n731       37.67    0.5214758    8.134572   M   hf   9      1\n732       41.28    0.4723469   11.538046   M   hf   9      1\n733       37.24    0.6217061    9.014193   M   hf  11      1\n734       49.45    0.6028061   14.362316   M   hf  11      1\n735       43.01    0.6522052   11.754554   M   hf  11      1\n736       47.75    0.8304621    7.465701   M   hf  11      1\n737       40.53    0.6453468    9.838946   M   hf  11      1\n738       42.18    0.5549514   12.699239   M   hf  11      1\n739       48.58    0.6737763   14.774443   M   hf  11      1\n740       35.67    0.5391676    9.093001   M   hf  11      1\n741       33.48    0.4326338    9.838618   M   hf  11      1\n742       45.86    0.6787500    9.851535   M   hf  11      1\n743       41.85    0.7555432    8.181848   M   hf  11      1\n744       34.47    0.5432489    6.974893   M   hf  11      1\n745       46.92    0.8570040    8.052314   M   hf  11      1\n746       38.23    0.7672173    7.579223   M   hf  11      1\n747       47.93    0.6810068   15.730581   M   hf  11      1\n748       39.84    0.6099138    9.570148   M   hf  11      1\n749       53.23    0.6530814   13.563459   M   hf  11      1\n750       47.93    0.5545449   14.471139   M   hf  11      1\n751       48.67    0.6286676   13.151642   M   hf  11      1\n752       47.08    0.6218792   10.503203   M   hf  11      1\n753       29.68    0.6581797    4.896448   M   hf  11      1\n754       50.87    0.7392700   11.635754   M   hf  11      1\n755       48.36    0.6207751   11.606809   M   hf  11      1\n756       50.39    0.6001097   11.042107   M   hf  11      1\n757       38.59    0.6328820    6.956791   M   hf  11      1\n758       38.51           NA          NA   M   hf  11      2\n759       46.48    0.6601341   11.540973   M   hf  11      2\n760       44.11    0.4868195   12.242745   M   hf  11      2\n761       45.11    0.6583403   10.422866   M   hf  11      2\n762       46.49    0.6338862   10.955168   M   hf  11      2\n763       47.00    0.7503652    9.911324   M   hf  11      2\n764       31.18    0.4602421    7.740294   M   hf  11      2\n765       46.67    0.6776419    8.758845   M   hf  11      2\n766       43.45    0.6458616    8.442680   M   hf  11      2\n767       36.52    0.6181475    6.242606   M   hf  11      2\n768       31.37    0.7678059    3.811867   M   hf  11      2\n769       39.74    0.6667387    4.738173   M   hf  11      2\n770       37.47    0.7900731    5.608837   M   hf  11      2\n771       25.65    0.5191188    4.700886   M   hf  11      2\n772       41.40    0.6739622    7.803863   M   hf  11      2\n773       34.16    0.6973688    5.579332   M   hf  11      2\n774       42.91    0.6751427    8.239802   M   hf  11      2\n775       42.44    0.6234010    8.816695   M   hf  11      2\n776       48.98    0.7178035   10.870578   M   hf  11      2\n777       33.10    0.6073667    7.701568   M   hf  11      2\n778       38.61    0.7490462    5.667483   M   hf  11      2\n779       46.41    0.6888560   10.072536   M   hf  11      2\n780       49.96    0.5191285   12.910024   M   hf  11      2\n\n#filtering out any null values. data is already mostly clean with just 8 null entries in the entire data set (4 each in two variables)\nmw_clean &lt;- mice_weights %&gt;%  dplyr::filter(!(is.na(bone_density)), !(is.na(percent_fat)))\n\n\n#checking distribution (boxplot) of percent_fat as a predictor of body_weight by sex.\nmw_clean %&gt;% ggplot(aes(percent_fat, body_weight)) + geom_boxplot() + facet_wrap(~sex)\n\nWarning: Continuous x aesthetic\nℹ did you forget `aes(group = ...)`?\n\n\n\n\n\n\n\n\n#checking distribution of diet as a predictor of body_weight by sex\nmw_clean %&gt;% ggplot(aes(diet, body_weight)) + geom_boxplot() + facet_wrap(~sex)\n\n\n\n\n\n\n\n#scatter of percent_fat as a predictor of body_weight by sex.\nmw_clean %&gt;% ggplot(aes(percent_fat, body_weight)) + geom_point() + facet_wrap(~sex)\n\n\n\n\n\n\n\n#scatter of bone_density as a predictor of body_weight by sex.\nmw_clean %&gt;% ggplot(aes(bone_density, body_weight)) + geom_point() + facet_wrap(~sex)\n\n\n\n\n\n\n\n\nI will be focusing on body weight as the dependent variable. The first boxplot explores the distribution of body weight by percent fat by each sex. Females have more outliers than males and lower average body weight. The second boxplot explores the distribution of body weight by diet dy sex. Again females have more outliers and lower average body weight than males. However, the HF diet produces higher body weights in both sexes than chow diet. The next scatter plot shows a positive relationship between percent fat and body weight. The last plot shows a loosely clustered positive relationship between bone density and body weight.I will continue fitting two models of body weight with percent fat and bone density as the predictor.\n\n#fitting two linear models for bodyweight by percent fat and bone density\nmw_pf_bw_fit = lm(body_weight~percent_fat, data = mw_clean)\nmw_bd_bw_fit = lm(body_weight~bone_density, data = mw_clean)\n\n#summary of each model\nsummary(mw_pf_bw_fit)\n\n\nCall:\nlm(formula = body_weight ~ percent_fat, data = mw_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-16.2594  -4.7686  -0.7525   4.5298  18.9356 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 21.51034    0.55808   38.54   &lt;2e-16 ***\npercent_fat  1.45918    0.05976   24.42   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.079 on 774 degrees of freedom\nMultiple R-squared:  0.4351,    Adjusted R-squared:  0.4344 \nF-statistic: 596.1 on 1 and 774 DF,  p-value: &lt; 2.2e-16\n\nsummary(mw_bd_bw_fit)\n\n\nCall:\nlm(formula = body_weight ~ bone_density, data = mw_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.0564  -5.5995  -0.8832   5.1219  29.5985 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    19.159      1.401   13.67   &lt;2e-16 ***\nbone_density   26.139      2.414   10.83   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.538 on 774 degrees of freedom\nMultiple R-squared:  0.1316,    Adjusted R-squared:  0.1305 \nF-statistic: 117.3 on 1 and 774 DF,  p-value: &lt; 2.2e-16\n\n\nThe two models’ predictors both have low significance for body weight. However, based on the r-squared values, the model with percent fat is a much better fit (0.43) than the bone density model (0.13)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My website and data analysis portfolio",
    "section": "",
    "text": "Hello\n\nNice to see you!\nWelcome to my website and data analysis portfolio.\n\nPlease use the Menu Bar above to look around.\nHave fun!"
  },
  {
    "objectID": "presentation-exercise/visualization-exercise.html",
    "href": "presentation-exercise/visualization-exercise.html",
    "title": "Visualization Exercise",
    "section": "",
    "text": "Using ChatGPT, I produced a publication worthy visualization similar to the one published here: https://fivethirtyeight.com/videos/the-ultimate-halloween-candy-power-ranking/ .\nThe following are the prompts and resulting code from CGPT:\nPrompt 1: Can you write code in R to recreate this chart? *attached screenshot of chart Result 1: A bare bones code structure that built its own data frame from a set of candy names and win percentages.\nPrompt 2: Can you recreate the chart using this data? *attached .csv file Result 2: Code that created the data frame from the csv file and a ggplot with only the top 18 ranking candies.\nPrompt 3: Can you make the plot interactive? Result 3: Same code as result 2, except using plotly to create the interactive chart instead of using ggplot.\nPrompt 4: Can you add their ranking number next to the candy name? Result 4: Same code as result 3, plus a new variable called rank that is displayed next to the candy name in the ploty plot.\nPrompt 5: Can you write code that displays the rank, candy name, then win percentage bar within a table? Result 5: A formattable table that displays the candy name, win percentage in a color coded single-bar graph, and rank number."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/eda.html",
    "href": "starter-analysis-exercise/code/eda-code/eda.html",
    "title": "An example exploratory analysis script",
    "section": "",
    "text": "This Quarto file loads the cleaned data and does some exploring.\nI’m only showing it the way where the code is included in the file. As described in the processing_code materials, I currently prefer the approach of having R code in a separate file and pulling it in.\nBut I already had this written and haven’t yet re-done it that way. Feel free to redo and send a pull request on GitHub :)\nAgain, it is largely a matter of preference and what makes the most sense to decide if one wants to have code inside Quarto files, or as separate R files. And sometimes, an R script with enough comments is good enough and one doesn’t need a Quarto file.\nAlso note that while here I split cleaning and exploring, this is iterative. You saw that as part of the processing, we already had to explore the data somewhat to understand how to clean it. In general, as you explore, you’ll find things that need cleaning. As you clean, you can explore more. Therefore, at times it might make more sense to combine the cleaning and exploring code parts into a single R or Quarto file. Or split things in any other logical way.\nAs part of the exploratory analysis, you should produce plots or tables or other summary quantities for the most interesting/important quantities in your data. Depending on the total number of variables in your dataset, explore all or some of the others. Figures produced here might be histograms or density plots, correlation plots, etc. Tables might summarize your data.\nStart by exploring one variable at a time. Then continue by creating plots or tables of the outcome(s) of interest and the predictor/exposure/input variables you are most interested in. If your dataset is small, you can do that for all variables.\nPlots produced here can be scatterplots, boxplots, violinplots, etc. Tables can be simple 2x2 tables or larger ones.\n\nSetup\n\n#load needed packages. make sure they are installed.\nlibrary(here) #for data loading/saving\n\nhere() starts at C:/Users/ameli/OneDrive/Documents/practicum 2/ameliatristan-p2-portfolio\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(skimr)\n\nWarning: package 'skimr' was built under R version 4.3.3\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.3\n\n\nLoad the data.\n\n#Path to data. Note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\n#load data\nmydata &lt;- readRDS(data_location)\n\n\n\nData exploration through tables\nShowing a bit of code to produce and save a summary table.\n\nsummary_df = skimr::skim(mydata)\nprint(summary_df)\n\n── Data Summary ────────────────────────\n                           Values\nName                       mydata\nNumber of rows             9     \nNumber of columns          5     \n_______________________          \nColumn type frequency:           \n  character                1     \n  factor                   1     \n  numeric                  3     \n________________________         \nGroup variables            None  \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Hair Color            0             1   2   7     0        7          0\n\n── Variable type: factor ───────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate ordered n_unique top_counts      \n1 Gender                0             1 FALSE          3 M: 4, F: 3, O: 2\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate  mean   sd  p0 p25 p50 p75 p100 hist \n1 Height                0             1 166.  16.0 133 156 166 178  183 ▂▁▃▃▇\n2 Weight                0             1  70.1 21.2  45  55  70  80  110 ▇▂▃▂▂\n3 Inseam                0             1  61.3 26.7   1  52  65  74   91 ▂▁▅▇▇\n\n# save to file\nsummarytable_file = here(\"starter-analysis-exercise\",\"results\", \"tables-files\", \"summarytable.rds\")\nsaveRDS(summary_df, file = summarytable_file)\n\nWe are saving the results to the results/tables folder. Structure the folders inside results such that they make sense for your specific analysis. Provide enough documentation that someone can understand what you are doing and what goes where. readme.md files inside each folder are a good idea.\n\n\nData exploration through figures\nHistogram plots for the continuous outcomes.\nHeight first.\n\np1 &lt;- mydata %&gt;% ggplot(aes(x=Height)) + geom_histogram() \nplot(p1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-distribution.png\")\nggsave(filename = figure_file, plot=p1) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow weights.\n\np2 &lt;- mydata %&gt;% ggplot(aes(x=Weight)) + geom_histogram() \nplot(p2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"weight-distribution.png\")\nggsave(filename = figure_file, plot=p2) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow height as function of weight.\n\np3 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight)) + geom_point() + geom_smooth(method='lm')\nplot(p3)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight.png\")\nggsave(filename = figure_file, plot=p3) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nOnce more height as function of weight, stratified by gender. Note that there is so little data, it’s a bit silly. But we’ll plot it anyway.\n\np4 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight, color = Gender)) + geom_point() + geom_smooth(method='lm')\nplot(p4)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight-stratified.png\")\nggsave(filename = figure_file, plot=p4) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\nWarning in qt((1 - level)/2, df): no non-missing arguments to max; returning\n-Inf\n\n\n\n\nNotes\nFor your own explorations, tables and figures can be “quick and dirty”. As long as you can see what’s going on, there is no need to polish them. That’s in contrast to figures you’ll produce for your final products (paper, report, presentation, website, etc.). Those should look as nice, polished and easy to understand as possible."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/readme.html",
    "href": "starter-analysis-exercise/code/eda-code/readme.html",
    "title": "Amelia Tristan's Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory data analysis (EDA) on the processed/cleaned data. The code produces a few tables and figures, which are saved in the appropriate results sub-folder."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/processingfile2.html",
    "href": "starter-analysis-exercise/code/processing-code/processingfile2.html",
    "title": "An example cleaning script",
    "section": "",
    "text": "Processing script\nThis Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.\n\n\nSetup\nLoad needed packages. make sure they are installed.\n\nlibrary(readxl) #for loading Excel files\nlibrary(dplyr) #for data processing/cleaning\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\nlibrary(skimr) #for nice visualization of data \n\nWarning: package 'skimr' was built under R version 4.3.3\n\nlibrary(here) #to set paths\n\nhere() starts at C:/Users/ameli/OneDrive/Documents/practicum 2/ameliatristan-p2-portfolio\n\n\n\n\nData loading\nNote that for functions that come from specific packages (instead of base R), I often specify both package and function like so: package::function() that’s not required one could just call the function specifying the package makes it clearer where the function “lives”, but it adds typing. You can do it either way.\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata2.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\n\nView(rawdata)\n\n\n\nCheck data\nFirst we can look at the codebook\n\ncodebook &lt;- readxl::read_excel(data_location, sheet =\"Codebook\")\nprint(codebook)\n\n# A tibble: 5 × 3\n  `Variable Name` `Variable Definition`                 `Allowed Values`        \n  &lt;chr&gt;           &lt;chr&gt;                                 &lt;chr&gt;                   \n1 Height          height in centimeters                 numeric value &gt;0 or NA  \n2 Weight          weight in kilograms                   numeric value &gt;0 or NA  \n3 Gender          identified gender (male/female/other) M/F/O/NA                \n4 Inseam Length   inseam in centimeters                 numeric value &gt;0 or NA  \n5 Hair Color      hair color, natural or other          black/brown/blond/white…\n\n\nSeveral ways of looking at the data\n\ndplyr::glimpse(rawdata)\n\nRows: 14\nColumns: 5\n$ Height       &lt;chr&gt; \"180\", \"175\", \"sixty\", \"178\", \"192\", \"6\", \"156\", \"166\", \"…\n$ Weight       &lt;dbl&gt; 80, 70, 60, 76, 90, 55, 90, 110, 54, 7000, NA, 45, 55, 50\n$ Gender       &lt;chr&gt; \"M\", \"O\", \"F\", \"F\", \"NA\", \"F\", \"O\", \"M\", \"N\", \"M\", \"F\", \"…\n$ Inseam       &lt;dbl&gt; 1, 74, 55, 91, 95, 89, 68, 62, 23, 49, 0, 50, 52, 65\n$ `Hair Color` &lt;chr&gt; \"black\", \"39\", \"brown\", \"l brown\", \"other\", \"black\", \"oth…\n\nsummary(rawdata)\n\n    Height              Weight          Gender              Inseam     \n Length:14          Min.   :  45.0   Length:14          Min.   : 0.00  \n Class :character   1st Qu.:  55.0   Class :character   1st Qu.:49.25  \n Mode  :character   Median :  70.0   Mode  :character   Median :58.50  \n                    Mean   : 602.7                      Mean   :55.29  \n                    3rd Qu.:  90.0                      3rd Qu.:72.50  \n                    Max.   :7000.0                      Max.   :95.00  \n                    NA's   :1                                          \n  Hair Color       \n Length:14         \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\nhead(rawdata)\n\n# A tibble: 6 × 5\n  Height Weight Gender Inseam `Hair Color`\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;       \n1 180        80 M           1 black       \n2 175        70 O          74 39          \n3 sixty      60 F          55 brown       \n4 178        76 F          91 l brown     \n5 192        90 NA         95 other       \n6 6          55 F          89 black       \n\nskimr::skim(rawdata)\n\n\nData summary\n\n\nName\nrawdata\n\n\nNumber of rows\n14\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHeight\n0\n1\n1\n5\n0\n13\n0\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nHair Color\n0\n1\n2\n7\n0\n9\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nWeight\n1\n0.93\n602.69\n1922.25\n45\n55.00\n70.0\n90.0\n7000\n▇▁▁▁▁\n\n\nInseam\n0\n1.00\n55.29\n30.08\n0\n49.25\n58.5\n72.5\n95\n▃▂▇▇▆\n\n\n\n\n\n\n\nCleaning\nBy inspecting the data as done above, we find some problems that need addressing:\nFirst, there is an entry for height which says “sixty” instead of a number. Does that mean it should be a numeric 60? It somehow doesn’t make sense since the weight is 60kg, which can’t happen for a 60cm person (a baby). Since we don’t know how to fix this, we might decide to remove the person. This “sixty” entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn’t very meaningful. So let’s fix that first.\n\nd1 &lt;- rawdata %&gt;% dplyr::filter( Height != \"sixty\" ) %&gt;% \n                  dplyr::mutate(Height = as.numeric(Height))\nskimr::skim(d1)\n\n\nData summary\n\n\nName\nd1\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nHair Color\n0\n1\n2\n7\n0\n8\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n151.62\n46.46\n6\n154.00\n165\n175\n192\n▁▁▁▂▇\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\nInseam\n0\n1.00\n55.31\n31.31\n0\n49.00\n62\n74\n95\n▃▂▆▇▆\n\n\n\n\nhist(d1$Height)\n\n\n\n\n\n\n\n\n\n# Correct the weight value of 7000 (assuming it's a typo, we will replace it with NA)\nd1 &lt;- d1 %&gt;%\n  dplyr::mutate(Weight = ifelse(Weight &gt; 500, NA, Weight))\n\n# Fill NA values in Weight with the median weight\nd1 &lt;- d1 %&gt;%\n  dplyr::mutate(Weight = ifelse(is.na(Weight), median(Weight, na.rm = TRUE), Weight))\n\n# Summarize the cleaned data\nskimr::skim(d1)\n\n\nData summary\n\n\nName\nd1\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nHair Color\n0\n1\n2\n7\n0\n8\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n151.62\n46.46\n6\n154\n165\n175\n192\n▁▁▁▂▇\n\n\nWeight\n0\n1\n70.38\n18.85\n45\n55\n70\n80\n110\n▇▅▃▃▂\n\n\nInseam\n0\n1\n55.31\n31.31\n0\n49\n62\n74\n95\n▃▂▆▇▆\n\n\n\n\n# Plot histogram of Height\nhist(d1$Height, main = \"Histogram of Heights\", xlab = \"Height (cm)\", ylab = \"Frequency\", col = \"blue\")\n\n\n\n\n\n\n\n\nNow we see that there is one person with a height of 6. That could be a typo, or someone mistakenly entered their height in feet. Since we unfortunately don’t know, we might need to remove this person, which we’ll do here.\n\nd2 &lt;- d1 %&gt;% dplyr::mutate( Height = replace(Height, Height==\"6\",round(6*30.48,0)) )\nskimr::skim(d2)\n\n\nData summary\n\n\nName\nd2\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nHair Color\n0\n1\n2\n7\n0\n8\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n165.23\n16.52\n133\n155\n166\n178\n192\n▂▇▆▆▃\n\n\nWeight\n0\n1\n70.38\n18.85\n45\n55\n70\n80\n110\n▇▅▃▃▂\n\n\nInseam\n0\n1\n55.31\n31.31\n0\n49\n62\n74\n95\n▃▂▆▇▆\n\n\n\n\n\nHeight values seem ok now.\nNow let’s look at the Weight variable. There is a person with weight of 7000, which is impossible, and one person with missing weight. To be able to analyze the data, we’ll remove those individuals as well.\n\nd3 &lt;- d2 %&gt;%  dplyr::filter(Weight != 7000) %&gt;% tidyr::drop_na()\nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nHair Color\n0\n1\n2\n7\n0\n8\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n165.23\n16.52\n133\n155\n166\n178\n192\n▂▇▆▆▃\n\n\nWeight\n0\n1\n70.38\n18.85\n45\n55\n70\n80\n110\n▇▅▃▃▂\n\n\nInseam\n0\n1\n55.31\n31.31\n0\n49\n62\n74\n95\n▃▂▆▇▆\n\n\n\n\n\nNow checking the Gender variable. Gender should be a categorical/factor variable but is loaded as character. We can fix that with simple base R code to mix things up.\n\nd3$Gender &lt;- as.factor(d3$Gender)  \nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHair Color\n0\n1\n2\n7\n0\n8\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n5\nM: 5, F: 4, O: 2, N: 1\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n165.23\n16.52\n133\n155\n166\n178\n192\n▂▇▆▆▃\n\n\nWeight\n0\n1\n70.38\n18.85\n45\n55\n70\n80\n110\n▇▅▃▃▂\n\n\nInseam\n0\n1\n55.31\n31.31\n0\n49\n62\n74\n95\n▃▂▆▇▆\n\n\n\n\n\nNow we see that there is another NA, but it’s not NA from R, instead it was loaded as character and is now considered as a category. Well proceed here by removing that individual with that NA entry. Since this keeps an empty category for Gender, I’m also using droplevels() to get rid of it.\n\nd4 &lt;- d3 %&gt;% dplyr::filter( !(Gender %in% c(\"NA\",\"N\")) ) %&gt;% droplevels()\nskimr::skim(d4)\n\n\nData summary\n\n\nName\nd4\n\n\nNumber of rows\n11\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHair Color\n0\n1\n2\n7\n0\n7\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n3\nM: 5, F: 4, O: 2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n163.73\n15.58\n133\n155.0\n166\n176.5\n183\n▂▂▃▆▇\n\n\nWeight\n0\n1\n70.09\n19.00\n45\n55.0\n70\n78.0\n110\n▇▆▃▂▂\n\n\nInseam\n0\n1\n54.64\n30.23\n0\n49.5\n62\n71.0\n91\n▅▁▇▇▇\n\n\n\n\n\nAll done, data is clean now.\nLet’s assign at the end to some final variable, this makes it easier to add further cleaning steps above.\n\nprocesseddata2 &lt;- d4\n\n\n\nSave data\nFinally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data: http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata\n\nsave_data_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata2.rds\")\nsaveRDS(processeddata2, file = save_data_location)\n\nNote the use of the here package and here command to specify a path relative to the main project directory, that is the folder that contains the .Rproj file. Always use this approach instead of hard-coding file paths that only exist on your computer.\n\n\nNotes\nRemoving anyone observation with “faulty” or missing data is one approach. It’s often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information)."
  },
  {
    "objectID": "starter-analysis-exercise/code/readme.html",
    "href": "starter-analysis-exercise/code/readme.html",
    "title": "Amelia Tristan's Data Analysis Portfolio",
    "section": "",
    "text": "Place your various R or Quarto files in the appropriate folders.\nYou can either have fewer large scripts, or multiple scripts that do only specific actions. Those can be R or Quarto files. In either case, document the scripts and what goes on in them so well that someone else (including future you) can easily figure out what is happening.\nThe scripts should load the appropriate data (e.g. raw or processed), perform actions, and save results (e.g. processed data, figures, computed values) in the appropriate folders. Document somewhere what inputs each script takes and where output is placed.\nIf scripts need to be run in a specific order, document this. Either as comments in the script, or in a separate text file such as this readme file. Ideally of course in both locations.\nDepending on your specific project, you might want to have further folders/sub-folders."
  },
  {
    "objectID": "starter-analysis-exercise/data/readme.html",
    "href": "starter-analysis-exercise/data/readme.html",
    "title": "Amelia Tristan's Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all data at various stages.\nThis data is being loaded/manipulated/changed/saved with code from the code folders.\nYou should place the raw data in the raw_data folder and not edit it. Ever!\nIdeally, load the raw data into R and do all changes there with code, so everything is automatically reproducible and documented.\nSometimes, you need to edit the files in the format you got. For instance, Excel files are sometimes so poorly formatted that it’s close to impossible to read them into R, or the persons you got the data from used color to code some information, which of course won’t import into R. In those cases, you might have to make modifications in a software other than R. If you need to make edits in whatever format you got the data (e.g. Excel), make a copy and place those copies in a separate folder, AND ONLY EDIT THOSE COPIES. Also, write down somewhere the edits you made.\nAdd as many sub-folders as suitable. If you only have a single processing step, one sub-folder for processed data is enough. If you have multiple stages of cleaning and processing, additional sub-folders might be useful. Adjust based on the complexity of your project.\nI suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data:\nhttp://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "",
    "text": "The structure below is one possible setup for a data analysis project (including the course project). For a manuscript, adjust as needed. You don’t need to have exactly these sections, but the content covering those sections should be addressed.\nThis uses MS Word as output format. See here for more information. You can switch to other formats, like html or pdf. See the Quarto documentation for other formats."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.1 General Background Information",
    "text": "2.1 General Background Information\nProvide enough background on your topic that others can understand the why and how of your analysis"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.2 Description of data and data source",
    "text": "2.2 Description of data and data source\nDescribe what the data is, what it contains, where it is from, etc. Eventually this might be part of a methods section."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#questionshypotheses-to-be-addressed",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#questionshypotheses-to-be-addressed",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "2.3 Questions/Hypotheses to be addressed",
    "text": "2.3 Questions/Hypotheses to be addressed\nState the research questions you plan to answer with this analysis.\nTo cite other work (important everywhere, but likely happens first in introduction), make sure your references are in the bibtex file specified in the YAML header above (here dataanalysis_template_references.bib) and have the right bibtex key. Then you can include like this:\nExamples of reproducible research projects can for instance be found in (McKay, Ebell, Billings, et al., 2020; McKay, Ebell, Dale, Shen, & Handel, 2020)"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-aquisition",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-aquisition",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.1 Data aquisition",
    "text": "3.1 Data aquisition\nAs applicable, explain where and how you got the data. If you directly import the data from an online source, you can combine this section with the next."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.2 Data import and cleaning",
    "text": "3.2 Data import and cleaning\nWrite code that reads in the file and cleans it so it’s ready for analysis. Since this will be fairly long code for most datasets, it might be a good idea to have it in one or several R scripts. If that is the case, explain here briefly what kind of cleaning/processing you do, and provide more details and well documented code somewhere (e.g. as supplement in a paper). All materials, including files that contain code, should be commented well so everyone can follow along."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.3 Statistical analysis",
    "text": "3.3 Statistical analysis\nExplain anything related to your statistical analyses."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#exploratorydescriptive-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#exploratorydescriptive-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.1 Exploratory/Descriptive analysis",
    "text": "4.1 Exploratory/Descriptive analysis\nUse a combination of text/tables/figures to explore and describe your data. Show the most important descriptive results here. Additional ones should go in the supplement. Even more can be in the R and Quarto files that are part of your project.\nTable 1 shows a summary of the data.\nNote the loading of the data providing a relative path using the ../../ notation. (Two dots means a folder up). You never want to specify an absolute path like C:\\ahandel\\myproject\\results\\ because if you share this with someone, it won’t work for them since they don’t have that path. You can also use the here R package to create paths. See examples of that below. I recommend the here package, but I’m showing the other approach here just in case you encounter it.\n\n\n\n\nTable 1: Data summary table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\ncharacter.min\ncharacter.max\ncharacter.empty\ncharacter.n_unique\ncharacter.whitespace\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\n\ncharacter\nHeight\n0\n1.0000000\n1\n5\n0\n13\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nGender\n0\n1.0000000\n1\n2\n0\n5\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\ncharacter\nHair Color\n0\n1.0000000\n2\n7\n0\n9\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nnumeric\nWeight\n1\n0.9285714\nNA\nNA\nNA\nNA\nNA\n602.69231\n1922.24636\n45\n55.00\n70.0\n90.0\n7000\n▇▁▁▁▁\n\n\nnumeric\nInseam\n0\n1.0000000\nNA\nNA\nNA\nNA\nNA\n55.28571\n30.08304\n0\n49.25\n58.5\n72.5\n95\n▃▂▇▇▆"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#basic-statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#basic-statistical-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.2 Basic statistical analysis",
    "text": "4.2 Basic statistical analysis\nTo get some further insight into your data, if reasonable you could compute simple statistics (e.g. simple models with 1 predictor) to look for associations between your outcome(s) and each individual predictor variable. Though note that unless you pre-specified the outcome and main exposure, any “p&lt;0.05 means statistical significance” interpretation is not valid.\nFigure 1 shows a scatterplot figure produced by one of the R scripts.\n\n\n\n\n\n\n\n\nFigure 1: Height and weight stratified by gender."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#full-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#full-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.3 Full analysis",
    "text": "4.3 Full analysis\nUse one or several suitable statistical/machine learning methods to analyze your data and to produce meaningful figures, tables, etc. This might again be code that is best placed in one or several separate R scripts that need to be well documented. You want the code to produce figures and data ready for display as tables, and save those. Then you load them here.\nExample Table 2 shows a summary of a linear model fit.\n\n\n\n\nTable 2: Linear model fit table.\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n172.0\nNaN\nNaN\nNaN\n\n\nWeight\n0.2\nNaN\nNaN\nNaN\n\n\nGenderM\n-28.0\nNaN\nNaN\nNaN\n\n\nGenderO\n-34.0\nNaN\nNaN\nNaN"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#summary-and-interpretation",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#summary-and-interpretation",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.1 Summary and Interpretation",
    "text": "5.1 Summary and Interpretation\nSummarize what you did, what you found and what it means."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#strengths-and-limitations",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#strengths-and-limitations",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.2 Strengths and Limitations",
    "text": "5.2 Strengths and Limitations\nDiscuss what you perceive as strengths and limitations of your analysis."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#conclusions",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#conclusions",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.3 Conclusions",
    "text": "5.3 Conclusions\nWhat are the main take-home messages?\nInclude citations in your Rmd file using bibtex, the list of references will automatically be placed at the end\nThis paper (Leek & Peng, 2015) discusses types of analyses.\nThese papers (McKay, Ebell, Billings, et al., 2020; McKay, Ebell, Dale, et al., 2020) are good examples of papers published using a fully reproducible setup similar to the one shown in this template.\nNote that this cited reference will show up at the end of the document, the reference formatting is determined by the CSL file specified in the YAML header. Many more style files for almost any journal are available. You also specify the location of your bibtex reference file in the YAML. You can call your reference file anything you like, I just used the generic word references.bib but giving it a more descriptive name is probably better."
  },
  {
    "objectID": "starter-analysis-exercise/results/figures/readme.html",
    "href": "starter-analysis-exercise/results/figures/readme.html",
    "title": "Amelia Tristan's Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all figures.\nYou can create further sub-folders if that makes sense."
  },
  {
    "objectID": "starter-analysis-exercise/results/tables-files/readme.html",
    "href": "starter-analysis-exercise/results/tables-files/readme.html",
    "title": "Amelia Tristan's Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all tables (generally stored as Rds files) and other files.\nYou can create further sub-folders if that makes sense."
  }
]